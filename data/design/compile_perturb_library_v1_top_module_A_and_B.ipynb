{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_scramble_nudt21_dist_pos_wt) = 55\n",
      "len(df_scramble_nudt21_dist_neu_wt) = 55\n",
      "len(df_scramble_nudt21_prox_pos_wt) = 55\n",
      "len(df_scramble_nudt21_prox_neu_wt) = 55\n",
      "len(df_scramble_nudt21_up_dist_pos_shuffle_1) = 275\n",
      "len(df_scramble_nudt21_up_dist_neu_shuffle_1) = 275\n",
      "len(df_scramble_nudt21_up_prox_pos_shuffle_1) = 275\n",
      "len(df_scramble_nudt21_up_prox_neu_shuffle_1) = 275\n",
      "len(df_scramble_nudt21_dn_dist_pos_shuffle_1) = 275\n",
      "len(df_scramble_nudt21_dn_dist_neu_shuffle_1) = 275\n",
      "len(df_scramble_nudt21_dn_prox_pos_shuffle_1) = 275\n",
      "len(df_scramble_nudt21_dn_prox_neu_shuffle_1) = 275\n",
      "len(df_scramble_nudt21_up_dist_pos_shuffle_1_and_2) = 275\n",
      "len(df_scramble_nudt21_up_prox_pos_shuffle_1_and_2) = 275\n",
      "\n",
      "len(df_scramble_nudt21) = 2970\n",
      "len(df_scramble_nudt21['pas_id'].unique()) = 220\n",
      "len(df_scramble_nudt21['seq'].unique()) = 2970\n",
      "\n",
      "df_scramble_nudt21['n_bcs'].sum() = 4250\n"
     ]
    }
   ],
   "source": [
    "#Load Aim 1.1: NUDT21 WT + Motif scrambling\n",
    "\n",
    "n_wt = 55\n",
    "n_wt_bcs = 5\n",
    "n_shuffled_to_bc = 5\n",
    "\n",
    "df_scramble_nudt21_up_dist_pos = pd.read_csv(\"samples/unif_bg_window_size_9_score_ix_2/apa_perturb_v3_cell_type_1_ix_0_cell_type_2_ix_6_score_ix_2_n_sequences_100_up_window_size_9_pos.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "df_scramble_nudt21_up_dist_neu = pd.read_csv(\"samples/unif_bg_window_size_9_score_ix_2/apa_perturb_v3_cell_type_1_ix_0_cell_type_2_ix_6_score_ix_2_n_sequences_100_up_window_size_9_neutral.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "\n",
    "df_scramble_nudt21_dn_dist_pos = pd.read_csv(\"samples/unif_bg_window_size_9_score_ix_2/apa_perturb_v3_cell_type_1_ix_0_cell_type_2_ix_6_score_ix_2_n_sequences_100_dn_window_size_9_pos.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "df_scramble_nudt21_dn_dist_neu = pd.read_csv(\"samples/unif_bg_window_size_9_score_ix_2/apa_perturb_v3_cell_type_1_ix_0_cell_type_2_ix_6_score_ix_2_n_sequences_100_dn_window_size_9_neutral.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "\n",
    "df_scramble_nudt21_up_prox_pos = pd.read_csv(\"samples/unif_bg_window_size_9_score_ix_0/apa_perturb_v3_cell_type_1_ix_0_cell_type_2_ix_6_score_ix_0_n_sequences_100_up_window_size_9_pos.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "df_scramble_nudt21_up_prox_neu = pd.read_csv(\"samples/unif_bg_window_size_9_score_ix_0/apa_perturb_v3_cell_type_1_ix_0_cell_type_2_ix_6_score_ix_0_n_sequences_100_up_window_size_9_neutral.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "\n",
    "df_scramble_nudt21_dn_prox_pos = pd.read_csv(\"samples/unif_bg_window_size_9_score_ix_0/apa_perturb_v3_cell_type_1_ix_0_cell_type_2_ix_6_score_ix_0_n_sequences_100_dn_window_size_9_pos.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "df_scramble_nudt21_dn_prox_neu = pd.read_csv(\"samples/unif_bg_window_size_9_score_ix_0/apa_perturb_v3_cell_type_1_ix_0_cell_type_2_ix_6_score_ix_0_n_sequences_100_dn_window_size_9_neutral.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "\n",
    "#Select sequence subsets\n",
    "\n",
    "#WT sequences\n",
    "df_scramble_nudt21_dist_pos_wt = df_scramble_nudt21_up_dist_pos.loc[df_scramble_nudt21_up_dist_pos['experiment'] == 'wt'].copy().reset_index(drop=True).iloc[:n_wt].copy().reset_index(drop=True)\n",
    "df_scramble_nudt21_dist_pos_wt['n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_scramble_nudt21_dist_pos_wt) = \" + str(len(df_scramble_nudt21_dist_pos_wt)))\n",
    "\n",
    "df_scramble_nudt21_dist_neu_wt = df_scramble_nudt21_up_dist_neu.loc[df_scramble_nudt21_up_dist_neu['experiment'] == 'wt'].copy().reset_index(drop=True).iloc[:n_wt].copy().reset_index(drop=True)\n",
    "df_scramble_nudt21_dist_neu_wt['n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_scramble_nudt21_dist_neu_wt) = \" + str(len(df_scramble_nudt21_dist_neu_wt)))\n",
    "\n",
    "df_scramble_nudt21_prox_pos_wt = df_scramble_nudt21_up_prox_pos.loc[df_scramble_nudt21_up_prox_pos['experiment'] == 'wt'].copy().reset_index(drop=True).iloc[:n_wt].copy().reset_index(drop=True)\n",
    "df_scramble_nudt21_prox_pos_wt['n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_scramble_nudt21_prox_pos_wt) = \" + str(len(df_scramble_nudt21_prox_pos_wt)))\n",
    "\n",
    "df_scramble_nudt21_prox_neu_wt = df_scramble_nudt21_up_prox_neu.loc[df_scramble_nudt21_up_prox_neu['experiment'] == 'wt'].copy().reset_index(drop=True).iloc[:n_wt].copy().reset_index(drop=True)\n",
    "df_scramble_nudt21_prox_neu_wt['n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_scramble_nudt21_prox_neu_wt) = \" + str(len(df_scramble_nudt21_prox_neu_wt)))\n",
    "\n",
    "#Shuffled regions (up)\n",
    "df_scramble_nudt21_up_dist_pos_shuffle_1 = df_scramble_nudt21_up_dist_pos.loc[df_scramble_nudt21_up_dist_pos['experiment'].str.contains(\"shuffle_1_p\")].copy().reset_index(drop=True)\n",
    "df_scramble_nudt21_up_dist_pos_shuffle_1['n_bc'] = 1\n",
    "df_scramble_nudt21_up_dist_pos_shuffle_1 = df_scramble_nudt21_up_dist_pos_shuffle_1.loc[df_scramble_nudt21_up_dist_pos_shuffle_1['pas_id'].isin(\n",
    "    df_scramble_nudt21_dist_pos_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "df_scramble_nudt21_up_dist_pos_shuffle_1.loc[df_scramble_nudt21_up_dist_pos_shuffle_1['pas_id'].isin(\n",
    "    df_scramble_nudt21_dist_pos_wt['pas_id'].values.tolist()[:n_shuffled_to_bc]\n",
    "), 'n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_scramble_nudt21_up_dist_pos_shuffle_1) = \" + str(len(df_scramble_nudt21_up_dist_pos_shuffle_1)))\n",
    "\n",
    "df_scramble_nudt21_up_dist_neu_shuffle_1 = df_scramble_nudt21_up_dist_neu.loc[df_scramble_nudt21_up_dist_neu['experiment'].str.contains(\"shuffle_1_p\")].copy().reset_index(drop=True)\n",
    "df_scramble_nudt21_up_dist_neu_shuffle_1['n_bc'] = 1\n",
    "df_scramble_nudt21_up_dist_neu_shuffle_1 = df_scramble_nudt21_up_dist_neu_shuffle_1.loc[df_scramble_nudt21_up_dist_neu_shuffle_1['pas_id'].isin(\n",
    "    df_scramble_nudt21_dist_neu_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "df_scramble_nudt21_up_dist_neu_shuffle_1.loc[df_scramble_nudt21_up_dist_neu_shuffle_1['pas_id'].isin(\n",
    "    df_scramble_nudt21_dist_neu_wt['pas_id'].values.tolist()[:n_shuffled_to_bc]\n",
    "), 'n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_scramble_nudt21_up_dist_neu_shuffle_1) = \" + str(len(df_scramble_nudt21_up_dist_neu_shuffle_1)))\n",
    "\n",
    "df_scramble_nudt21_up_prox_pos_shuffle_1 = df_scramble_nudt21_up_prox_pos.loc[df_scramble_nudt21_up_prox_pos['experiment'].str.contains(\"shuffle_1_p\")].copy().reset_index(drop=True)\n",
    "df_scramble_nudt21_up_prox_pos_shuffle_1['n_bc'] = 1\n",
    "df_scramble_nudt21_up_prox_pos_shuffle_1 = df_scramble_nudt21_up_prox_pos_shuffle_1.loc[df_scramble_nudt21_up_prox_pos_shuffle_1['pas_id'].isin(\n",
    "    df_scramble_nudt21_prox_pos_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "df_scramble_nudt21_up_prox_pos_shuffle_1.loc[df_scramble_nudt21_up_prox_pos_shuffle_1['pas_id'].isin(\n",
    "    df_scramble_nudt21_prox_pos_wt['pas_id'].values.tolist()[:n_shuffled_to_bc]\n",
    "), 'n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_scramble_nudt21_up_prox_pos_shuffle_1) = \" + str(len(df_scramble_nudt21_up_prox_pos_shuffle_1)))\n",
    "\n",
    "df_scramble_nudt21_up_prox_neu_shuffle_1 = df_scramble_nudt21_up_prox_neu.loc[df_scramble_nudt21_up_prox_neu['experiment'].str.contains(\"shuffle_1_p\")].copy().reset_index(drop=True)\n",
    "df_scramble_nudt21_up_prox_neu_shuffle_1['n_bc'] = 1\n",
    "df_scramble_nudt21_up_prox_neu_shuffle_1 = df_scramble_nudt21_up_prox_neu_shuffle_1.loc[df_scramble_nudt21_up_prox_neu_shuffle_1['pas_id'].isin(\n",
    "    df_scramble_nudt21_prox_neu_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "df_scramble_nudt21_up_prox_neu_shuffle_1.loc[df_scramble_nudt21_up_prox_neu_shuffle_1['pas_id'].isin(\n",
    "    df_scramble_nudt21_prox_neu_wt['pas_id'].values.tolist()[:n_shuffled_to_bc]\n",
    "), 'n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_scramble_nudt21_up_prox_neu_shuffle_1) = \" + str(len(df_scramble_nudt21_up_prox_neu_shuffle_1)))\n",
    "\n",
    "#Shuffled regions (dn)\n",
    "df_scramble_nudt21_dn_dist_pos_shuffle_1 = df_scramble_nudt21_dn_dist_pos.loc[df_scramble_nudt21_dn_dist_pos['experiment'].str.contains(\"shuffle_1_p\")].copy().reset_index(drop=True)\n",
    "df_scramble_nudt21_dn_dist_pos_shuffle_1['n_bc'] = 1\n",
    "df_scramble_nudt21_dn_dist_pos_shuffle_1 = df_scramble_nudt21_dn_dist_pos_shuffle_1.loc[df_scramble_nudt21_dn_dist_pos_shuffle_1['pas_id'].isin(\n",
    "    df_scramble_nudt21_dist_pos_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_scramble_nudt21_dn_dist_pos_shuffle_1) = \" + str(len(df_scramble_nudt21_dn_dist_pos_shuffle_1)))\n",
    "\n",
    "df_scramble_nudt21_dn_dist_neu_shuffle_1 = df_scramble_nudt21_dn_dist_neu.loc[df_scramble_nudt21_dn_dist_neu['experiment'].str.contains(\"shuffle_1_p\")].copy().reset_index(drop=True)\n",
    "df_scramble_nudt21_dn_dist_neu_shuffle_1['n_bc'] = 1\n",
    "df_scramble_nudt21_dn_dist_neu_shuffle_1 = df_scramble_nudt21_dn_dist_neu_shuffle_1.loc[df_scramble_nudt21_dn_dist_neu_shuffle_1['pas_id'].isin(\n",
    "    df_scramble_nudt21_dist_neu_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_scramble_nudt21_dn_dist_neu_shuffle_1) = \" + str(len(df_scramble_nudt21_dn_dist_neu_shuffle_1)))\n",
    "\n",
    "df_scramble_nudt21_dn_prox_pos_shuffle_1 = df_scramble_nudt21_dn_prox_pos.loc[df_scramble_nudt21_dn_prox_pos['experiment'].str.contains(\"shuffle_1_p\")].copy().reset_index(drop=True)\n",
    "df_scramble_nudt21_dn_prox_pos_shuffle_1['n_bc'] = 1\n",
    "df_scramble_nudt21_dn_prox_pos_shuffle_1 = df_scramble_nudt21_dn_prox_pos_shuffle_1.loc[df_scramble_nudt21_dn_prox_pos_shuffle_1['pas_id'].isin(\n",
    "    df_scramble_nudt21_prox_pos_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_scramble_nudt21_dn_prox_pos_shuffle_1) = \" + str(len(df_scramble_nudt21_dn_prox_pos_shuffle_1)))\n",
    "\n",
    "df_scramble_nudt21_dn_prox_neu_shuffle_1 = df_scramble_nudt21_dn_prox_neu.loc[df_scramble_nudt21_dn_prox_neu['experiment'].str.contains(\"shuffle_1_p\")].copy().reset_index(drop=True)\n",
    "df_scramble_nudt21_dn_prox_neu_shuffle_1['n_bc'] = 1\n",
    "df_scramble_nudt21_dn_prox_neu_shuffle_1 = df_scramble_nudt21_dn_prox_neu_shuffle_1.loc[df_scramble_nudt21_dn_prox_neu_shuffle_1['pas_id'].isin(\n",
    "    df_scramble_nudt21_prox_neu_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_scramble_nudt21_dn_prox_neu_shuffle_1) = \" + str(len(df_scramble_nudt21_dn_prox_neu_shuffle_1)))\n",
    "\n",
    "#Shuffled regions, 1 and 2 (up)\n",
    "df_scramble_nudt21_up_dist_pos_shuffle_1_and_2 = df_scramble_nudt21_up_dist_pos.loc[df_scramble_nudt21_up_dist_pos['experiment'].str.contains(\"shuffle_1_and_2\")].copy().reset_index(drop=True)\n",
    "df_scramble_nudt21_up_dist_pos_shuffle_1_and_2['n_bc'] = 1\n",
    "df_scramble_nudt21_up_dist_pos_shuffle_1_and_2 = df_scramble_nudt21_up_dist_pos_shuffle_1_and_2.loc[df_scramble_nudt21_up_dist_pos_shuffle_1_and_2['pas_id'].isin(\n",
    "    df_scramble_nudt21_dist_pos_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_scramble_nudt21_up_dist_pos_shuffle_1_and_2) = \" + str(len(df_scramble_nudt21_up_dist_pos_shuffle_1_and_2)))\n",
    "\n",
    "df_scramble_nudt21_up_prox_pos_shuffle_1_and_2 = df_scramble_nudt21_up_prox_pos.loc[df_scramble_nudt21_up_prox_pos['experiment'].str.contains(\"shuffle_1_and_2\")].copy().reset_index(drop=True)\n",
    "df_scramble_nudt21_up_prox_pos_shuffle_1_and_2['n_bc'] = 1\n",
    "df_scramble_nudt21_up_prox_pos_shuffle_1_and_2 = df_scramble_nudt21_up_prox_pos_shuffle_1_and_2.loc[df_scramble_nudt21_up_prox_pos_shuffle_1_and_2['pas_id'].isin(\n",
    "    df_scramble_nudt21_prox_pos_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_scramble_nudt21_up_prox_pos_shuffle_1_and_2) = \" + str(len(df_scramble_nudt21_up_prox_pos_shuffle_1_and_2)))\n",
    "\n",
    "#Append sub-aim metadata column\n",
    "df_scramble_nudt21_dist_pos_wt['subaim'] = \"distal_positive\"\n",
    "df_scramble_nudt21_up_dist_pos_shuffle_1['subaim'] = \"distal_positive\"\n",
    "df_scramble_nudt21_dn_dist_pos_shuffle_1['subaim'] = \"distal_positive\"\n",
    "df_scramble_nudt21_up_dist_pos_shuffle_1_and_2['subaim'] = \"distal_positive\"\n",
    "\n",
    "df_scramble_nudt21_dist_neu_wt['subaim'] = \"distal_neutral\"\n",
    "df_scramble_nudt21_up_dist_neu_shuffle_1['subaim'] = \"distal_neutral\"\n",
    "df_scramble_nudt21_dn_dist_neu_shuffle_1['subaim'] = \"distal_neutral\"\n",
    "\n",
    "df_scramble_nudt21_prox_pos_wt['subaim'] = \"proximal_positive\"\n",
    "df_scramble_nudt21_up_prox_pos_shuffle_1['subaim'] = \"proximal_positive\"\n",
    "df_scramble_nudt21_dn_prox_pos_shuffle_1['subaim'] = \"proximal_positive\"\n",
    "df_scramble_nudt21_up_prox_pos_shuffle_1_and_2['subaim'] = \"proximal_positive\"\n",
    "\n",
    "df_scramble_nudt21_prox_neu_wt['subaim'] = \"proximal_neutral\"\n",
    "df_scramble_nudt21_up_prox_neu_shuffle_1['subaim'] = \"proximal_neutral\"\n",
    "df_scramble_nudt21_dn_prox_neu_shuffle_1['subaim'] = \"proximal_neutral\"\n",
    "\n",
    "#Concatenate all subexperiment dataframes\n",
    "\n",
    "df_scramble_nudt21 = pd.concat([\n",
    "    df_scramble_nudt21_dist_pos_wt,\n",
    "    df_scramble_nudt21_up_dist_pos_shuffle_1,\n",
    "    df_scramble_nudt21_dn_dist_pos_shuffle_1,\n",
    "    df_scramble_nudt21_up_dist_pos_shuffle_1_and_2,\n",
    "    \n",
    "    df_scramble_nudt21_dist_neu_wt,\n",
    "    df_scramble_nudt21_up_dist_neu_shuffle_1,\n",
    "    df_scramble_nudt21_dn_dist_neu_shuffle_1,\n",
    "    \n",
    "    df_scramble_nudt21_prox_pos_wt,\n",
    "    df_scramble_nudt21_up_prox_pos_shuffle_1,\n",
    "    df_scramble_nudt21_dn_prox_pos_shuffle_1,\n",
    "    df_scramble_nudt21_up_prox_pos_shuffle_1_and_2,\n",
    "    \n",
    "    df_scramble_nudt21_prox_neu_wt,\n",
    "    df_scramble_nudt21_up_prox_neu_shuffle_1,\n",
    "    df_scramble_nudt21_dn_prox_neu_shuffle_1,\n",
    "]).copy().reset_index(drop=True)\n",
    "\n",
    "print(\"\")\n",
    "print(\"len(df_scramble_nudt21) = \" + str(len(df_scramble_nudt21)))\n",
    "print(\"len(df_scramble_nudt21['pas_id'].unique()) = \" + str(len(df_scramble_nudt21['pas_id'].unique())))\n",
    "print(\"len(df_scramble_nudt21['seq'].unique()) = \" + str(len(df_scramble_nudt21['seq'].unique())))\n",
    "print(\"\")\n",
    "print(\"df_scramble_nudt21['n_bcs'].sum() = \" + str(int(df_scramble_nudt21['n_bc'].sum())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_scramble_cstf3_dist_pos_wt) = 55\n",
      "len(df_scramble_cstf3_dist_neu_wt) = 55\n",
      "len(df_scramble_cstf3_prox_pos_wt) = 55\n",
      "len(df_scramble_cstf3_prox_neu_wt) = 55\n",
      "len(df_scramble_cstf3_dn_dist_pos_shuffle_1) = 275\n",
      "len(df_scramble_cstf3_dn_dist_neu_shuffle_1) = 275\n",
      "len(df_scramble_cstf3_dn_prox_pos_shuffle_1) = 275\n",
      "len(df_scramble_cstf3_dn_prox_neu_shuffle_1) = 275\n",
      "\n",
      "len(df_scramble_cstf3) = 1320\n",
      "len(df_scramble_cstf3['pas_id'].unique()) = 220\n",
      "len(df_scramble_cstf3['seq'].unique()) = 1320\n",
      "\n",
      "df_scramble_cstf3['n_bcs'].sum() = 2600\n"
     ]
    }
   ],
   "source": [
    "#Load Aim 1.2: CSTF3 WT + Motif scrambling\n",
    "\n",
    "n_wt = 55\n",
    "n_wt_bcs = 5\n",
    "n_shuffled_to_bc = 5\n",
    "\n",
    "df_scramble_cstf3_dn_dist_pos = pd.read_csv(\"samples/unif_bg_window_size_9_score_ix_2/apa_perturb_v3_cell_type_1_ix_0_cell_type_2_ix_4_score_ix_2_n_sequences_100_dn_window_size_9_pos.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "df_scramble_cstf3_dn_dist_neu = pd.read_csv(\"samples/unif_bg_window_size_9_score_ix_2/apa_perturb_v3_cell_type_1_ix_0_cell_type_2_ix_4_score_ix_2_n_sequences_100_dn_window_size_9_neutral.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "\n",
    "df_scramble_cstf3_dn_prox_pos = pd.read_csv(\"samples/unif_bg_window_size_9_score_ix_0/apa_perturb_v3_cell_type_1_ix_0_cell_type_2_ix_4_score_ix_0_n_sequences_100_dn_window_size_9_pos.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "df_scramble_cstf3_dn_prox_neu = pd.read_csv(\"samples/unif_bg_window_size_9_score_ix_0/apa_perturb_v3_cell_type_1_ix_0_cell_type_2_ix_4_score_ix_0_n_sequences_100_dn_window_size_9_neutral.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "\n",
    "#Select sequence subsets\n",
    "\n",
    "#WT sequences\n",
    "df_scramble_cstf3_dist_pos_wt = df_scramble_cstf3_dn_dist_pos.loc[df_scramble_cstf3_dn_dist_pos['experiment'] == 'wt'].copy().reset_index(drop=True).iloc[:n_wt].copy().reset_index(drop=True)\n",
    "df_scramble_cstf3_dist_pos_wt['n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_scramble_cstf3_dist_pos_wt) = \" + str(len(df_scramble_cstf3_dist_pos_wt)))\n",
    "\n",
    "df_scramble_cstf3_dist_neu_wt = df_scramble_cstf3_dn_dist_neu.loc[df_scramble_cstf3_dn_dist_neu['experiment'] == 'wt'].copy().reset_index(drop=True).iloc[:n_wt].copy().reset_index(drop=True)\n",
    "df_scramble_cstf3_dist_neu_wt['n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_scramble_cstf3_dist_neu_wt) = \" + str(len(df_scramble_cstf3_dist_neu_wt)))\n",
    "\n",
    "df_scramble_cstf3_prox_pos_wt = df_scramble_cstf3_dn_prox_pos.loc[df_scramble_cstf3_dn_prox_pos['experiment'] == 'wt'].copy().reset_index(drop=True).iloc[:n_wt].copy().reset_index(drop=True)\n",
    "df_scramble_cstf3_prox_pos_wt['n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_scramble_cstf3_prox_pos_wt) = \" + str(len(df_scramble_cstf3_prox_pos_wt)))\n",
    "\n",
    "df_scramble_cstf3_prox_neu_wt = df_scramble_cstf3_dn_prox_neu.loc[df_scramble_cstf3_dn_prox_neu['experiment'] == 'wt'].copy().reset_index(drop=True).iloc[:n_wt].copy().reset_index(drop=True)\n",
    "df_scramble_cstf3_prox_neu_wt['n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_scramble_cstf3_prox_neu_wt) = \" + str(len(df_scramble_cstf3_prox_neu_wt)))\n",
    "\n",
    "#Shuffled regions (dn)\n",
    "df_scramble_cstf3_dn_dist_pos_shuffle_1 = df_scramble_cstf3_dn_dist_pos.loc[df_scramble_cstf3_dn_dist_pos['experiment'].str.contains(\"shuffle_1_p\")].copy().reset_index(drop=True)\n",
    "df_scramble_cstf3_dn_dist_pos_shuffle_1['n_bc'] = 1\n",
    "df_scramble_cstf3_dn_dist_pos_shuffle_1 = df_scramble_cstf3_dn_dist_pos_shuffle_1.loc[df_scramble_cstf3_dn_dist_pos_shuffle_1['pas_id'].isin(\n",
    "    df_scramble_cstf3_dist_pos_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "df_scramble_cstf3_dn_dist_pos_shuffle_1.loc[df_scramble_cstf3_dn_dist_pos_shuffle_1['pas_id'].isin(\n",
    "    df_scramble_cstf3_dist_pos_wt['pas_id'].values.tolist()[:n_shuffled_to_bc]\n",
    "), 'n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_scramble_cstf3_dn_dist_pos_shuffle_1) = \" + str(len(df_scramble_cstf3_dn_dist_pos_shuffle_1)))\n",
    "\n",
    "df_scramble_cstf3_dn_dist_neu_shuffle_1 = df_scramble_cstf3_dn_dist_neu.loc[df_scramble_cstf3_dn_dist_neu['experiment'].str.contains(\"shuffle_1_p\")].copy().reset_index(drop=True)\n",
    "df_scramble_cstf3_dn_dist_neu_shuffle_1['n_bc'] = 1\n",
    "df_scramble_cstf3_dn_dist_neu_shuffle_1 = df_scramble_cstf3_dn_dist_neu_shuffle_1.loc[df_scramble_cstf3_dn_dist_neu_shuffle_1['pas_id'].isin(\n",
    "    df_scramble_cstf3_dist_neu_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "df_scramble_cstf3_dn_dist_neu_shuffle_1.loc[df_scramble_cstf3_dn_dist_neu_shuffle_1['pas_id'].isin(\n",
    "    df_scramble_cstf3_dist_neu_wt['pas_id'].values.tolist()[:n_shuffled_to_bc]\n",
    "), 'n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_scramble_cstf3_dn_dist_neu_shuffle_1) = \" + str(len(df_scramble_cstf3_dn_dist_neu_shuffle_1)))\n",
    "\n",
    "df_scramble_cstf3_dn_prox_pos_shuffle_1 = df_scramble_cstf3_dn_prox_pos.loc[df_scramble_cstf3_dn_prox_pos['experiment'].str.contains(\"shuffle_1_p\")].copy().reset_index(drop=True)\n",
    "df_scramble_cstf3_dn_prox_pos_shuffle_1['n_bc'] = 1\n",
    "df_scramble_cstf3_dn_prox_pos_shuffle_1 = df_scramble_cstf3_dn_prox_pos_shuffle_1.loc[df_scramble_cstf3_dn_prox_pos_shuffle_1['pas_id'].isin(\n",
    "    df_scramble_cstf3_prox_pos_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "df_scramble_cstf3_dn_prox_pos_shuffle_1.loc[df_scramble_cstf3_dn_prox_pos_shuffle_1['pas_id'].isin(\n",
    "    df_scramble_cstf3_prox_pos_wt['pas_id'].values.tolist()[:n_shuffled_to_bc]\n",
    "), 'n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_scramble_cstf3_dn_prox_pos_shuffle_1) = \" + str(len(df_scramble_cstf3_dn_prox_pos_shuffle_1)))\n",
    "\n",
    "df_scramble_cstf3_dn_prox_neu_shuffle_1 = df_scramble_cstf3_dn_prox_neu.loc[df_scramble_cstf3_dn_prox_neu['experiment'].str.contains(\"shuffle_1_p\")].copy().reset_index(drop=True)\n",
    "df_scramble_cstf3_dn_prox_neu_shuffle_1['n_bc'] = 1\n",
    "df_scramble_cstf3_dn_prox_neu_shuffle_1 = df_scramble_cstf3_dn_prox_neu_shuffle_1.loc[df_scramble_cstf3_dn_prox_neu_shuffle_1['pas_id'].isin(\n",
    "    df_scramble_cstf3_prox_neu_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "df_scramble_cstf3_dn_prox_neu_shuffle_1.loc[df_scramble_cstf3_dn_prox_neu_shuffle_1['pas_id'].isin(\n",
    "    df_scramble_cstf3_prox_neu_wt['pas_id'].values.tolist()[:n_shuffled_to_bc]\n",
    "), 'n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_scramble_cstf3_dn_prox_neu_shuffle_1) = \" + str(len(df_scramble_cstf3_dn_prox_neu_shuffle_1)))\n",
    "\n",
    "#Append sub-aim metadata column\n",
    "df_scramble_cstf3_dist_pos_wt['subaim'] = \"distal_positive\"\n",
    "df_scramble_cstf3_dn_dist_pos_shuffle_1['subaim'] = \"distal_positive\"\n",
    "\n",
    "df_scramble_cstf3_dist_neu_wt['subaim'] = \"distal_neutral\"\n",
    "df_scramble_cstf3_dn_dist_neu_shuffle_1['subaim'] = \"distal_neutral\"\n",
    "\n",
    "df_scramble_cstf3_prox_pos_wt['subaim'] = \"proximal_positive\"\n",
    "df_scramble_cstf3_dn_prox_pos_shuffle_1['subaim'] = \"proximal_positive\"\n",
    "\n",
    "df_scramble_cstf3_prox_neu_wt['subaim'] = \"proximal_neutral\"\n",
    "df_scramble_cstf3_dn_prox_neu_shuffle_1['subaim'] = \"proximal_neutral\"\n",
    "\n",
    "#Concatenate all subexperiment dataframes\n",
    "\n",
    "df_scramble_cstf3 = pd.concat([\n",
    "    df_scramble_cstf3_dist_pos_wt,\n",
    "    df_scramble_cstf3_dn_dist_pos_shuffle_1,\n",
    "    \n",
    "    df_scramble_cstf3_dist_neu_wt,\n",
    "    df_scramble_cstf3_dn_dist_neu_shuffle_1,\n",
    "    \n",
    "    df_scramble_cstf3_prox_pos_wt,\n",
    "    df_scramble_cstf3_dn_prox_pos_shuffle_1,\n",
    "    \n",
    "    df_scramble_cstf3_prox_neu_wt,\n",
    "    df_scramble_cstf3_dn_prox_neu_shuffle_1,\n",
    "]).copy().reset_index(drop=True)\n",
    "\n",
    "print(\"\")\n",
    "print(\"len(df_scramble_cstf3) = \" + str(len(df_scramble_cstf3)))\n",
    "print(\"len(df_scramble_cstf3['pas_id'].unique()) = \" + str(len(df_scramble_cstf3['pas_id'].unique())))\n",
    "print(\"len(df_scramble_cstf3['seq'].unique()) = \" + str(len(df_scramble_cstf3['seq'].unique())))\n",
    "print(\"\")\n",
    "print(\"df_scramble_cstf3['n_bcs'].sum() = \" + str(int(df_scramble_cstf3['n_bc'].sum())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_scramble_rbbp6_dist_neg_wt) = 55\n",
      "len(df_scramble_rbbp6_dist_neu_wt) = 55\n",
      "len(df_scramble_rbbp6_dn_dist_neg_shuffle_1) = 275\n",
      "len(df_scramble_rbbp6_dn_dist_neu_shuffle_1) = 275\n",
      "len(df_scramble_rbbp6_dn_dist_neg_shuffle_2) = 275\n",
      "\n",
      "len(df_scramble_rbbp6) = 935\n",
      "len(df_scramble_rbbp6['pas_id'].unique()) = 110\n",
      "len(df_scramble_rbbp6['seq'].unique()) = 935\n",
      "\n",
      "df_scramble_rbbp6['n_bcs'].sum() = 1475\n"
     ]
    }
   ],
   "source": [
    "#Load Aim 1.3: RBBP6 WT + Motif scrambling\n",
    "\n",
    "n_wt = 55\n",
    "n_wt_bcs = 5\n",
    "n_shuffled_to_bc = 5\n",
    "\n",
    "df_scramble_rbbp6_dn_dist_neg = pd.read_csv(\"samples/unif_bg_window_size_9_score_ix_2/apa_perturb_v3_cell_type_1_ix_0_cell_type_2_ix_7_score_ix_2_n_sequences_100_cse_window_size_9_neg.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "df_scramble_rbbp6_dn_dist_neu = pd.read_csv(\"samples/unif_bg_window_size_9_score_ix_2/apa_perturb_v3_cell_type_1_ix_0_cell_type_2_ix_7_score_ix_2_n_sequences_100_cse_window_size_9_neutral.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "\n",
    "#Select sequence subsets\n",
    "\n",
    "#WT sequences\n",
    "df_scramble_rbbp6_dist_neg_wt = df_scramble_rbbp6_dn_dist_neg.loc[df_scramble_rbbp6_dn_dist_neg['experiment'] == 'wt'].copy().reset_index(drop=True).iloc[:n_wt].copy().reset_index(drop=True)\n",
    "df_scramble_rbbp6_dist_neg_wt['n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_scramble_rbbp6_dist_neg_wt) = \" + str(len(df_scramble_rbbp6_dist_neg_wt)))\n",
    "\n",
    "df_scramble_rbbp6_dist_neu_wt = df_scramble_rbbp6_dn_dist_neu.loc[df_scramble_rbbp6_dn_dist_neu['experiment'] == 'wt'].copy().reset_index(drop=True).iloc[:n_wt].copy().reset_index(drop=True)\n",
    "df_scramble_rbbp6_dist_neu_wt['n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_scramble_rbbp6_dist_neu_wt) = \" + str(len(df_scramble_rbbp6_dist_neu_wt)))\n",
    "\n",
    "#Shuffled regions (dn; 1)\n",
    "df_scramble_rbbp6_dn_dist_neg_shuffle_1 = df_scramble_rbbp6_dn_dist_neg.loc[df_scramble_rbbp6_dn_dist_neg['experiment'].str.contains(\"shuffle_1_p\")].copy().reset_index(drop=True)\n",
    "df_scramble_rbbp6_dn_dist_neg_shuffle_1['n_bc'] = 1\n",
    "df_scramble_rbbp6_dn_dist_neg_shuffle_1 = df_scramble_rbbp6_dn_dist_neg_shuffle_1.loc[df_scramble_rbbp6_dn_dist_neg_shuffle_1['pas_id'].isin(\n",
    "    df_scramble_rbbp6_dist_neg_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_scramble_rbbp6_dn_dist_neg_shuffle_1) = \" + str(len(df_scramble_rbbp6_dn_dist_neg_shuffle_1)))\n",
    "\n",
    "df_scramble_rbbp6_dn_dist_neu_shuffle_1 = df_scramble_rbbp6_dn_dist_neu.loc[df_scramble_rbbp6_dn_dist_neu['experiment'].str.contains(\"shuffle_1_p\")].copy().reset_index(drop=True)\n",
    "df_scramble_rbbp6_dn_dist_neu_shuffle_1['n_bc'] = 1\n",
    "df_scramble_rbbp6_dn_dist_neu_shuffle_1 = df_scramble_rbbp6_dn_dist_neu_shuffle_1.loc[df_scramble_rbbp6_dn_dist_neu_shuffle_1['pas_id'].isin(\n",
    "    df_scramble_rbbp6_dist_neu_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_scramble_rbbp6_dn_dist_neu_shuffle_1) = \" + str(len(df_scramble_rbbp6_dn_dist_neu_shuffle_1)))\n",
    "\n",
    "#Shuffled regions (dn; 2)\n",
    "df_scramble_rbbp6_dn_dist_neg_shuffle_2 = df_scramble_rbbp6_dn_dist_neg.loc[df_scramble_rbbp6_dn_dist_neg['experiment'].str.contains(\"shuffle_2_p\")].copy().reset_index(drop=True)\n",
    "df_scramble_rbbp6_dn_dist_neg_shuffle_2['n_bc'] = 1\n",
    "df_scramble_rbbp6_dn_dist_neg_shuffle_2 = df_scramble_rbbp6_dn_dist_neg_shuffle_2.loc[df_scramble_rbbp6_dn_dist_neg_shuffle_2['pas_id'].isin(\n",
    "    df_scramble_rbbp6_dist_neg_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "df_scramble_rbbp6_dn_dist_neg_shuffle_2.loc[df_scramble_rbbp6_dn_dist_neg_shuffle_2['pas_id'].isin(\n",
    "    df_scramble_rbbp6_dist_neg_wt['pas_id'].values.tolist()[:n_shuffled_to_bc]\n",
    "), 'n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_scramble_rbbp6_dn_dist_neg_shuffle_2) = \" + str(len(df_scramble_rbbp6_dn_dist_neg_shuffle_2)))\n",
    "\n",
    "#Append sub-aim metadata column\n",
    "df_scramble_rbbp6_dist_neg_wt['subaim'] = \"distal_negative\"\n",
    "df_scramble_rbbp6_dn_dist_neg_shuffle_1['subaim'] = \"distal_negative\"\n",
    "df_scramble_rbbp6_dn_dist_neg_shuffle_2['subaim'] = \"distal_negative\"\n",
    "\n",
    "df_scramble_rbbp6_dist_neu_wt['subaim'] = \"distal_neutral\"\n",
    "df_scramble_rbbp6_dn_dist_neu_shuffle_1['subaim'] = \"distal_neutral\"\n",
    "\n",
    "#Concatenate all subexperiment dataframes\n",
    "\n",
    "df_scramble_rbbp6 = pd.concat([\n",
    "    df_scramble_rbbp6_dist_neg_wt,\n",
    "    df_scramble_rbbp6_dn_dist_neg_shuffle_1,\n",
    "    df_scramble_rbbp6_dn_dist_neg_shuffle_2,\n",
    "    \n",
    "    df_scramble_rbbp6_dist_neu_wt,\n",
    "    df_scramble_rbbp6_dn_dist_neu_shuffle_1,\n",
    "]).copy().reset_index(drop=True)\n",
    "\n",
    "print(\"\")\n",
    "print(\"len(df_scramble_rbbp6) = \" + str(len(df_scramble_rbbp6)))\n",
    "print(\"len(df_scramble_rbbp6['pas_id'].unique()) = \" + str(len(df_scramble_rbbp6['pas_id'].unique())))\n",
    "print(\"len(df_scramble_rbbp6['seq'].unique()) = \" + str(len(df_scramble_rbbp6['seq'].unique())))\n",
    "print(\"\")\n",
    "print(\"df_scramble_rbbp6['n_bcs'].sum() = \" + str(int(df_scramble_rbbp6['n_bc'].sum())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_abl_nudt21_at_wt) = 70\n",
      "len(df_abl_nudt21_at_shuffle_1) = 350\n",
      "len(df_abl_nudt21_at_shuffle_2) = 350\n",
      "len(df_abl_nudt21_at_shuffle_null) = 350\n",
      "len(df_abl_nudt21_at_shuffle_1_and_2) = 350\n",
      "len(df_abl_nudt21_at_shuffle_1_and_null) = 350\n",
      "\n",
      "len(df_abl_nudt21_at) = 1820\n",
      "len(df_abl_nudt21_at['pas_id'].unique()) = 70\n",
      "len(df_abl_nudt21_at['seq'].unique()) = 1820\n",
      "\n",
      "df_abl_nudt21_at['n_bcs'].sum() = 2100\n"
     ]
    }
   ],
   "source": [
    "#Load Aim 2.1.1: NUDT21 ablation (AT)\n",
    "\n",
    "n_wt = 70\n",
    "n_wt_bcs = 5\n",
    "\n",
    "df_abl_nudt21_at = pd.read_csv(\"samples/epistasis_ablate_TGTA_flank_AT/cell_type_1_ix_0_cell_type_2_ix_6_score_ix_2_n_sequences_100_window_size_6.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "\n",
    "#Select sequence subsets\n",
    "\n",
    "#WT sequences\n",
    "df_abl_nudt21_at_wt = df_abl_nudt21_at.loc[df_abl_nudt21_at['experiment'] == 'wt'].copy().reset_index(drop=True).iloc[:n_wt].copy().reset_index(drop=True)\n",
    "df_abl_nudt21_at_wt['n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_abl_nudt21_at_wt) = \" + str(len(df_abl_nudt21_at_wt)))\n",
    "\n",
    "#Shuffled motif 1\n",
    "df_abl_nudt21_at_shuffle_1 = df_abl_nudt21_at.loc[df_abl_nudt21_at['experiment'].str.contains(\"shuffle_1_p\")].copy().reset_index(drop=True)\n",
    "df_abl_nudt21_at_shuffle_1['n_bc'] = 1\n",
    "df_abl_nudt21_at_shuffle_1 = df_abl_nudt21_at_shuffle_1.loc[df_abl_nudt21_at_shuffle_1['pas_id'].isin(\n",
    "    df_abl_nudt21_at_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_abl_nudt21_at_shuffle_1) = \" + str(len(df_abl_nudt21_at_shuffle_1)))\n",
    "\n",
    "#Shuffled motif 2\n",
    "df_abl_nudt21_at_shuffle_2 = df_abl_nudt21_at.loc[df_abl_nudt21_at['experiment'].str.contains(\"shuffle_2_p\")].copy().reset_index(drop=True)\n",
    "df_abl_nudt21_at_shuffle_2['n_bc'] = 1\n",
    "df_abl_nudt21_at_shuffle_2 = df_abl_nudt21_at_shuffle_2.loc[df_abl_nudt21_at_shuffle_2['pas_id'].isin(\n",
    "    df_abl_nudt21_at_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_abl_nudt21_at_shuffle_2) = \" + str(len(df_abl_nudt21_at_shuffle_2)))\n",
    "\n",
    "#Shuffled motif null\n",
    "df_abl_nudt21_at_shuffle_null = df_abl_nudt21_at.loc[df_abl_nudt21_at['experiment'].str.contains(\"shuffle_null_p\")].copy().reset_index(drop=True)\n",
    "df_abl_nudt21_at_shuffle_null['n_bc'] = 1\n",
    "df_abl_nudt21_at_shuffle_null = df_abl_nudt21_at_shuffle_null.loc[df_abl_nudt21_at_shuffle_null['pas_id'].isin(\n",
    "    df_abl_nudt21_at_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_abl_nudt21_at_shuffle_null) = \" + str(len(df_abl_nudt21_at_shuffle_null)))\n",
    "\n",
    "#Shuffled motif 1 and 2\n",
    "df_abl_nudt21_at_shuffle_1_and_2 = df_abl_nudt21_at.loc[df_abl_nudt21_at['experiment'].str.contains(\"shuffle_1_and_2_p\")].copy().reset_index(drop=True)\n",
    "df_abl_nudt21_at_shuffle_1_and_2['n_bc'] = 1\n",
    "df_abl_nudt21_at_shuffle_1_and_2 = df_abl_nudt21_at_shuffle_1_and_2.loc[df_abl_nudt21_at_shuffle_1_and_2['pas_id'].isin(\n",
    "    df_abl_nudt21_at_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_abl_nudt21_at_shuffle_1_and_2) = \" + str(len(df_abl_nudt21_at_shuffle_1_and_2)))\n",
    "\n",
    "#Shuffled motif 1 and null\n",
    "df_abl_nudt21_at_shuffle_1_and_null = df_abl_nudt21_at.loc[df_abl_nudt21_at['experiment'].str.contains(\"shuffle_1_and_null_p\")].copy().reset_index(drop=True)\n",
    "df_abl_nudt21_at_shuffle_1_and_null['n_bc'] = 1\n",
    "df_abl_nudt21_at_shuffle_1_and_null = df_abl_nudt21_at_shuffle_1_and_null.loc[df_abl_nudt21_at_shuffle_1_and_null['pas_id'].isin(\n",
    "    df_abl_nudt21_at_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_abl_nudt21_at_shuffle_1_and_null) = \" + str(len(df_abl_nudt21_at_shuffle_1_and_null)))\n",
    "\n",
    "#Concatenate all subexperiment dataframes\n",
    "\n",
    "df_abl_nudt21_at = pd.concat([\n",
    "    df_abl_nudt21_at_wt,\n",
    "    df_abl_nudt21_at_shuffle_1,\n",
    "    df_abl_nudt21_at_shuffle_2,\n",
    "    df_abl_nudt21_at_shuffle_null,\n",
    "    df_abl_nudt21_at_shuffle_1_and_2,\n",
    "    df_abl_nudt21_at_shuffle_1_and_null,\n",
    "]).copy().reset_index(drop=True)\n",
    "\n",
    "#Append sub-aim metadata column\n",
    "df_abl_nudt21_at['subaim'] = \"at\"\n",
    "\n",
    "print(\"\")\n",
    "print(\"len(df_abl_nudt21_at) = \" + str(len(df_abl_nudt21_at)))\n",
    "print(\"len(df_abl_nudt21_at['pas_id'].unique()) = \" + str(len(df_abl_nudt21_at['pas_id'].unique())))\n",
    "print(\"len(df_abl_nudt21_at['seq'].unique()) = \" + str(len(df_abl_nudt21_at['seq'].unique())))\n",
    "print(\"\")\n",
    "print(\"df_abl_nudt21_at['n_bcs'].sum() = \" + str(int(df_abl_nudt21_at['n_bc'].sum())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_abl_nudt21_gc_wt) = 20\n",
      "len(df_abl_nudt21_gc_shuffle_1) = 100\n",
      "len(df_abl_nudt21_gc_shuffle_2) = 100\n",
      "len(df_abl_nudt21_gc_shuffle_null) = 100\n",
      "len(df_abl_nudt21_gc_shuffle_1_and_2) = 100\n",
      "len(df_abl_nudt21_gc_shuffle_1_and_null) = 100\n",
      "\n",
      "len(df_abl_nudt21_gc) = 520\n",
      "len(df_abl_nudt21_gc['pas_id'].unique()) = 20\n",
      "len(df_abl_nudt21_gc['seq'].unique()) = 520\n",
      "\n",
      "df_abl_nudt21_gc['n_bcs'].sum() = 600\n"
     ]
    }
   ],
   "source": [
    "#Load Aim 2.1.2: NUDT21 ablation (GC)\n",
    "\n",
    "n_wt = 20\n",
    "n_wt_bcs = 5\n",
    "\n",
    "df_abl_nudt21_gc = pd.read_csv(\"samples/epistasis_ablate_TGTA_flank_GC/cell_type_1_ix_0_cell_type_2_ix_6_score_ix_2_n_sequences_20_window_size_6.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "\n",
    "#Select sequence subsets\n",
    "\n",
    "#WT sequences\n",
    "df_abl_nudt21_gc_wt = df_abl_nudt21_gc.loc[df_abl_nudt21_gc['experiment'] == 'wt'].copy().reset_index(drop=True).iloc[:n_wt].copy().reset_index(drop=True)\n",
    "df_abl_nudt21_gc_wt['n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_abl_nudt21_gc_wt) = \" + str(len(df_abl_nudt21_gc_wt)))\n",
    "\n",
    "#Shuffled motif 1\n",
    "df_abl_nudt21_gc_shuffle_1 = df_abl_nudt21_gc.loc[df_abl_nudt21_gc['experiment'].str.contains(\"shuffle_1_p\")].copy().reset_index(drop=True)\n",
    "df_abl_nudt21_gc_shuffle_1['n_bc'] = 1\n",
    "df_abl_nudt21_gc_shuffle_1 = df_abl_nudt21_gc_shuffle_1.loc[df_abl_nudt21_gc_shuffle_1['pas_id'].isin(\n",
    "    df_abl_nudt21_gc_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_abl_nudt21_gc_shuffle_1) = \" + str(len(df_abl_nudt21_gc_shuffle_1)))\n",
    "\n",
    "#Shuffled motif 2\n",
    "df_abl_nudt21_gc_shuffle_2 = df_abl_nudt21_gc.loc[df_abl_nudt21_gc['experiment'].str.contains(\"shuffle_2_p\")].copy().reset_index(drop=True)\n",
    "df_abl_nudt21_gc_shuffle_2['n_bc'] = 1\n",
    "df_abl_nudt21_gc_shuffle_2 = df_abl_nudt21_gc_shuffle_2.loc[df_abl_nudt21_gc_shuffle_2['pas_id'].isin(\n",
    "    df_abl_nudt21_gc_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_abl_nudt21_gc_shuffle_2) = \" + str(len(df_abl_nudt21_gc_shuffle_2)))\n",
    "\n",
    "#Shuffled motif null\n",
    "df_abl_nudt21_gc_shuffle_null = df_abl_nudt21_gc.loc[df_abl_nudt21_gc['experiment'].str.contains(\"shuffle_null_p\")].copy().reset_index(drop=True)\n",
    "df_abl_nudt21_gc_shuffle_null['n_bc'] = 1\n",
    "df_abl_nudt21_gc_shuffle_null = df_abl_nudt21_gc_shuffle_null.loc[df_abl_nudt21_gc_shuffle_null['pas_id'].isin(\n",
    "    df_abl_nudt21_gc_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_abl_nudt21_gc_shuffle_null) = \" + str(len(df_abl_nudt21_gc_shuffle_null)))\n",
    "\n",
    "#Shuffled motif 1 and 2\n",
    "df_abl_nudt21_gc_shuffle_1_and_2 = df_abl_nudt21_gc.loc[df_abl_nudt21_gc['experiment'].str.contains(\"shuffle_1_and_2_p\")].copy().reset_index(drop=True)\n",
    "df_abl_nudt21_gc_shuffle_1_and_2['n_bc'] = 1\n",
    "df_abl_nudt21_gc_shuffle_1_and_2 = df_abl_nudt21_gc_shuffle_1_and_2.loc[df_abl_nudt21_gc_shuffle_1_and_2['pas_id'].isin(\n",
    "    df_abl_nudt21_gc_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_abl_nudt21_gc_shuffle_1_and_2) = \" + str(len(df_abl_nudt21_gc_shuffle_1_and_2)))\n",
    "\n",
    "#Shuffled motif 1 and null\n",
    "df_abl_nudt21_gc_shuffle_1_and_null = df_abl_nudt21_gc.loc[df_abl_nudt21_gc['experiment'].str.contains(\"shuffle_1_and_null_p\")].copy().reset_index(drop=True)\n",
    "df_abl_nudt21_gc_shuffle_1_and_null['n_bc'] = 1\n",
    "df_abl_nudt21_gc_shuffle_1_and_null = df_abl_nudt21_gc_shuffle_1_and_null.loc[df_abl_nudt21_gc_shuffle_1_and_null['pas_id'].isin(\n",
    "    df_abl_nudt21_gc_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_abl_nudt21_gc_shuffle_1_and_null) = \" + str(len(df_abl_nudt21_gc_shuffle_1_and_null)))\n",
    "\n",
    "#Concatenate all subexperiment dataframes\n",
    "\n",
    "df_abl_nudt21_gc = pd.concat([\n",
    "    df_abl_nudt21_gc_wt,\n",
    "    df_abl_nudt21_gc_shuffle_1,\n",
    "    df_abl_nudt21_gc_shuffle_2,\n",
    "    df_abl_nudt21_gc_shuffle_null,\n",
    "    df_abl_nudt21_gc_shuffle_1_and_2,\n",
    "    df_abl_nudt21_gc_shuffle_1_and_null,\n",
    "]).copy().reset_index(drop=True)\n",
    "\n",
    "#Append sub-aim metadata column\n",
    "df_abl_nudt21_gc['subaim'] = \"gc\"\n",
    "\n",
    "print(\"\")\n",
    "print(\"len(df_abl_nudt21_gc) = \" + str(len(df_abl_nudt21_gc)))\n",
    "print(\"len(df_abl_nudt21_gc['pas_id'].unique()) = \" + str(len(df_abl_nudt21_gc['pas_id'].unique())))\n",
    "print(\"len(df_abl_nudt21_gc['seq'].unique()) = \" + str(len(df_abl_nudt21_gc['seq'].unique())))\n",
    "print(\"\")\n",
    "print(\"df_abl_nudt21_gc['n_bcs'].sum() = \" + str(int(df_abl_nudt21_gc['n_bc'].sum())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_abl_rbbp6_wt) = 50\n",
      "len(df_abl_rbbp6_shuffle_1) = 250\n",
      "len(df_abl_rbbp6_shuffle_2) = 250\n",
      "len(df_abl_rbbp6_shuffle_null) = 250\n",
      "len(df_abl_rbbp6_shuffle_1_and_2) = 250\n",
      "len(df_abl_rbbp6_shuffle_1_and_null) = 250\n",
      "\n",
      "len(df_abl_rbbp6) = 1300\n",
      "len(df_abl_rbbp6['pas_id'].unique()) = 50\n",
      "len(df_abl_rbbp6['seq'].unique()) = 1300\n",
      "\n",
      "df_abl_rbbp6['n_bcs'].sum() = 1500\n"
     ]
    }
   ],
   "source": [
    "#Load Aim 2.2: RBBP6 ablation\n",
    "\n",
    "n_wt = 50\n",
    "n_wt_bcs = 5\n",
    "\n",
    "df_abl_rbbp6 = pd.read_csv(\"samples/epistasis_ablate_AWTAAA_GT/cell_type_1_ix_0_cell_type_2_ix_7_score_ix_2_n_sequences_100_window_size_10.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "\n",
    "#Select sequence subsets\n",
    "\n",
    "#WT sequences\n",
    "df_abl_rbbp6_wt = df_abl_rbbp6.loc[df_abl_rbbp6['experiment'] == 'wt'].copy().reset_index(drop=True).iloc[:n_wt].copy().reset_index(drop=True)\n",
    "df_abl_rbbp6_wt['n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_abl_rbbp6_wt) = \" + str(len(df_abl_rbbp6_wt)))\n",
    "\n",
    "#Shuffled motif 1\n",
    "df_abl_rbbp6_shuffle_1 = df_abl_rbbp6.loc[df_abl_rbbp6['experiment'].str.contains(\"shuffle_1_p\")].copy().reset_index(drop=True)\n",
    "df_abl_rbbp6_shuffle_1['n_bc'] = 1\n",
    "df_abl_rbbp6_shuffle_1 = df_abl_rbbp6_shuffle_1.loc[df_abl_rbbp6_shuffle_1['pas_id'].isin(\n",
    "    df_abl_rbbp6_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_abl_rbbp6_shuffle_1) = \" + str(len(df_abl_rbbp6_shuffle_1)))\n",
    "\n",
    "#Shuffled motif 2\n",
    "df_abl_rbbp6_shuffle_2 = df_abl_rbbp6.loc[df_abl_rbbp6['experiment'].str.contains(\"shuffle_2_p\")].copy().reset_index(drop=True)\n",
    "df_abl_rbbp6_shuffle_2['n_bc'] = 1\n",
    "df_abl_rbbp6_shuffle_2 = df_abl_rbbp6_shuffle_2.loc[df_abl_rbbp6_shuffle_2['pas_id'].isin(\n",
    "    df_abl_rbbp6_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_abl_rbbp6_shuffle_2) = \" + str(len(df_abl_rbbp6_shuffle_2)))\n",
    "\n",
    "#Shuffled motif null\n",
    "df_abl_rbbp6_shuffle_null = df_abl_rbbp6.loc[df_abl_rbbp6['experiment'].str.contains(\"shuffle_null_p\")].copy().reset_index(drop=True)\n",
    "df_abl_rbbp6_shuffle_null['n_bc'] = 1\n",
    "df_abl_rbbp6_shuffle_null = df_abl_rbbp6_shuffle_null.loc[df_abl_rbbp6_shuffle_null['pas_id'].isin(\n",
    "    df_abl_rbbp6_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_abl_rbbp6_shuffle_null) = \" + str(len(df_abl_rbbp6_shuffle_null)))\n",
    "\n",
    "#Shuffled motif 1 and 2\n",
    "df_abl_rbbp6_shuffle_1_and_2 = df_abl_rbbp6.loc[df_abl_rbbp6['experiment'].str.contains(\"shuffle_1_and_2_p\")].copy().reset_index(drop=True)\n",
    "df_abl_rbbp6_shuffle_1_and_2['n_bc'] = 1\n",
    "df_abl_rbbp6_shuffle_1_and_2 = df_abl_rbbp6_shuffle_1_and_2.loc[df_abl_rbbp6_shuffle_1_and_2['pas_id'].isin(\n",
    "    df_abl_rbbp6_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_abl_rbbp6_shuffle_1_and_2) = \" + str(len(df_abl_rbbp6_shuffle_1_and_2)))\n",
    "\n",
    "#Shuffled motif 1 and null\n",
    "df_abl_rbbp6_shuffle_1_and_null = df_abl_rbbp6.loc[df_abl_rbbp6['experiment'].str.contains(\"shuffle_1_and_null_p\")].copy().reset_index(drop=True)\n",
    "df_abl_rbbp6_shuffle_1_and_null['n_bc'] = 1\n",
    "df_abl_rbbp6_shuffle_1_and_null = df_abl_rbbp6_shuffle_1_and_null.loc[df_abl_rbbp6_shuffle_1_and_null['pas_id'].isin(\n",
    "    df_abl_rbbp6_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_abl_rbbp6_shuffle_1_and_null) = \" + str(len(df_abl_rbbp6_shuffle_1_and_null)))\n",
    "\n",
    "#Concatenate all subexperiment dataframes\n",
    "\n",
    "df_abl_rbbp6 = pd.concat([\n",
    "    df_abl_rbbp6_wt,\n",
    "    df_abl_rbbp6_shuffle_1,\n",
    "    df_abl_rbbp6_shuffle_2,\n",
    "    df_abl_rbbp6_shuffle_null,\n",
    "    df_abl_rbbp6_shuffle_1_and_2,\n",
    "    df_abl_rbbp6_shuffle_1_and_null,\n",
    "]).copy().reset_index(drop=True)\n",
    "\n",
    "#Append sub-aim metadata column\n",
    "df_abl_rbbp6['subaim'] = \"no_subaim\"\n",
    "\n",
    "print(\"\")\n",
    "print(\"len(df_abl_rbbp6) = \" + str(len(df_abl_rbbp6)))\n",
    "print(\"len(df_abl_rbbp6['pas_id'].unique()) = \" + str(len(df_abl_rbbp6['pas_id'].unique())))\n",
    "print(\"len(df_abl_rbbp6['seq'].unique()) = \" + str(len(df_abl_rbbp6['seq'].unique())))\n",
    "print(\"\")\n",
    "print(\"df_abl_rbbp6['n_bcs'].sum() = \" + str(int(df_abl_rbbp6['n_bc'].sum())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_ins_nudt21_at_comp_wt) = 10\n",
      "len(df_ins_nudt21_at_comp_insert_1) = 370\n",
      "len(df_ins_nudt21_at_comp_insert_1_and_2) = 250\n",
      "\n",
      "len(df_ins_nudt21_at_comp) = 630\n",
      "len(df_ins_nudt21_at_comp['pas_id'].unique()) = 10\n",
      "len(df_ins_nudt21_at_comp['seq'].unique()) = 629\n",
      "\n",
      "df_ins_nudt21_at_comp['n_bcs'].sum() = 670\n"
     ]
    }
   ],
   "source": [
    "#Load Aim 2.3.1: NUDT21 insertion (AT comp)\n",
    "\n",
    "n_wt = 10\n",
    "n_wt_bcs = 5\n",
    "\n",
    "df_ins_nudt21_at_comp = pd.read_csv(\"samples/epistasis_insert_TGTA_AT_comp/cell_type_1_ix_0_cell_type_2_ix_6_score_ix_2_n_sequences_10.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "\n",
    "#Select sequence subsets\n",
    "\n",
    "#WT sequences\n",
    "df_ins_nudt21_at_comp_wt = df_ins_nudt21_at_comp.loc[df_ins_nudt21_at_comp['experiment'] == 'wt'].copy().reset_index(drop=True).iloc[:n_wt].copy().reset_index(drop=True)\n",
    "df_ins_nudt21_at_comp_wt['n_bc'] = n_wt_bcs\n",
    "\n",
    "df_ins_nudt21_at_comp = df_ins_nudt21_at_comp.loc[df_ins_nudt21_at_comp['experiment'] != 'wt'].copy().reset_index(drop=True)\n",
    "\n",
    "print(\"len(df_ins_nudt21_at_comp_wt) = \" + str(len(df_ins_nudt21_at_comp_wt)))\n",
    "\n",
    "#Insert one motif\n",
    "df_ins_nudt21_at_comp_insert_1 = df_ins_nudt21_at_comp.loc[~df_ins_nudt21_at_comp['experiment'].str.contains(\"_and_\")].copy().reset_index(drop=True)\n",
    "df_ins_nudt21_at_comp_insert_1['n_bc'] = 1\n",
    "df_ins_nudt21_at_comp_insert_1 = df_ins_nudt21_at_comp_insert_1.loc[df_ins_nudt21_at_comp_insert_1['pas_id'].isin(\n",
    "    df_ins_nudt21_at_comp_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_ins_nudt21_at_comp_insert_1) = \" + str(len(df_ins_nudt21_at_comp_insert_1)))\n",
    "\n",
    "#Insert both motifs\n",
    "df_ins_nudt21_at_comp_insert_1_and_2 = df_ins_nudt21_at_comp.loc[df_ins_nudt21_at_comp['experiment'].str.contains(\"_and_\")].copy().reset_index(drop=True)\n",
    "df_ins_nudt21_at_comp_insert_1_and_2['n_bc'] = 1\n",
    "df_ins_nudt21_at_comp_insert_1_and_2 = df_ins_nudt21_at_comp_insert_1_and_2.loc[df_ins_nudt21_at_comp_insert_1_and_2['pas_id'].isin(\n",
    "    df_ins_nudt21_at_comp_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_ins_nudt21_at_comp_insert_1_and_2) = \" + str(len(df_ins_nudt21_at_comp_insert_1_and_2)))\n",
    "\n",
    "#Concatenate all subexperiment dataframes\n",
    "\n",
    "df_ins_nudt21_at_comp = pd.concat([\n",
    "    df_ins_nudt21_at_comp_wt,\n",
    "    df_ins_nudt21_at_comp_insert_1,\n",
    "    df_ins_nudt21_at_comp_insert_1_and_2,\n",
    "]).copy().reset_index(drop=True)\n",
    "\n",
    "#Append sub-aim metadata column\n",
    "df_ins_nudt21_at_comp['subaim'] = \"at_comp\"\n",
    "\n",
    "print(\"\")\n",
    "print(\"len(df_ins_nudt21_at_comp) = \" + str(len(df_ins_nudt21_at_comp)))\n",
    "print(\"len(df_ins_nudt21_at_comp['pas_id'].unique()) = \" + str(len(df_ins_nudt21_at_comp['pas_id'].unique())))\n",
    "print(\"len(df_ins_nudt21_at_comp['seq'].unique()) = \" + str(len(df_ins_nudt21_at_comp['seq'].unique())))\n",
    "print(\"\")\n",
    "print(\"df_ins_nudt21_at_comp['n_bcs'].sum() = \" + str(int(df_ins_nudt21_at_comp['n_bc'].sum())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_ins_nudt21_gc_comp_wt) = 10\n",
      "len(df_ins_nudt21_gc_comp_insert_1) = 380\n",
      "len(df_ins_nudt21_gc_comp_insert_1_and_2) = 250\n",
      "\n",
      "len(df_ins_nudt21_gc_comp) = 640\n",
      "len(df_ins_nudt21_gc_comp['pas_id'].unique()) = 10\n",
      "len(df_ins_nudt21_gc_comp['seq'].unique()) = 640\n",
      "\n",
      "df_ins_nudt21_gc_comp['n_bcs'].sum() = 680\n"
     ]
    }
   ],
   "source": [
    "#Load Aim 2.3.2: NUDT21 insertion (GC comp)\n",
    "\n",
    "n_wt = 10\n",
    "n_wt_bcs = 5\n",
    "\n",
    "df_ins_nudt21_gc_comp = pd.read_csv(\"samples/epistasis_insert_TGTA_GC_comp/cell_type_1_ix_0_cell_type_2_ix_6_score_ix_2_n_sequences_10.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "\n",
    "#Select sequence subsets\n",
    "\n",
    "#WT sequences\n",
    "df_ins_nudt21_gc_comp_wt = df_ins_nudt21_gc_comp.loc[df_ins_nudt21_gc_comp['experiment'] == 'wt'].copy().reset_index(drop=True).iloc[:n_wt].copy().reset_index(drop=True)\n",
    "df_ins_nudt21_gc_comp_wt['n_bc'] = n_wt_bcs\n",
    "\n",
    "df_ins_nudt21_gc_comp = df_ins_nudt21_gc_comp.loc[df_ins_nudt21_gc_comp['experiment'] != 'wt'].copy().reset_index(drop=True)\n",
    "\n",
    "print(\"len(df_ins_nudt21_gc_comp_wt) = \" + str(len(df_ins_nudt21_gc_comp_wt)))\n",
    "\n",
    "#Insert one motif\n",
    "df_ins_nudt21_gc_comp_insert_1 = df_ins_nudt21_gc_comp.loc[~df_ins_nudt21_gc_comp['experiment'].str.contains(\"_and_\")].copy().reset_index(drop=True)\n",
    "df_ins_nudt21_gc_comp_insert_1['n_bc'] = 1\n",
    "df_ins_nudt21_gc_comp_insert_1 = df_ins_nudt21_gc_comp_insert_1.loc[df_ins_nudt21_gc_comp_insert_1['pas_id'].isin(\n",
    "    df_ins_nudt21_gc_comp_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_ins_nudt21_gc_comp_insert_1) = \" + str(len(df_ins_nudt21_gc_comp_insert_1)))\n",
    "\n",
    "#Insert both motifs\n",
    "df_ins_nudt21_gc_comp_insert_1_and_2 = df_ins_nudt21_gc_comp.loc[df_ins_nudt21_gc_comp['experiment'].str.contains(\"_and_\")].copy().reset_index(drop=True)\n",
    "df_ins_nudt21_gc_comp_insert_1_and_2['n_bc'] = 1\n",
    "df_ins_nudt21_gc_comp_insert_1_and_2 = df_ins_nudt21_gc_comp_insert_1_and_2.loc[df_ins_nudt21_gc_comp_insert_1_and_2['pas_id'].isin(\n",
    "    df_ins_nudt21_gc_comp_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_ins_nudt21_gc_comp_insert_1_and_2) = \" + str(len(df_ins_nudt21_gc_comp_insert_1_and_2)))\n",
    "\n",
    "#Concatenate all subexperiment dataframes\n",
    "\n",
    "df_ins_nudt21_gc_comp = pd.concat([\n",
    "    df_ins_nudt21_gc_comp_wt,\n",
    "    df_ins_nudt21_gc_comp_insert_1,\n",
    "    df_ins_nudt21_gc_comp_insert_1_and_2,\n",
    "]).copy().reset_index(drop=True)\n",
    "\n",
    "#Append sub-aim metadata column\n",
    "df_ins_nudt21_gc_comp['subaim'] = \"gc_comp\"\n",
    "\n",
    "print(\"\")\n",
    "print(\"len(df_ins_nudt21_gc_comp) = \" + str(len(df_ins_nudt21_gc_comp)))\n",
    "print(\"len(df_ins_nudt21_gc_comp['pas_id'].unique()) = \" + str(len(df_ins_nudt21_gc_comp['pas_id'].unique())))\n",
    "print(\"len(df_ins_nudt21_gc_comp['seq'].unique()) = \" + str(len(df_ins_nudt21_gc_comp['seq'].unique())))\n",
    "print(\"\")\n",
    "print(\"df_ins_nudt21_gc_comp['n_bcs'].sum() = \" + str(int(df_ins_nudt21_gc_comp['n_bc'].sum())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_ins_nudt21_at_flank_wt) = 10\n",
      "len(df_ins_nudt21_at_flank_insert_1) = 370\n",
      "len(df_ins_nudt21_at_flank_insert_1_and_2) = 250\n",
      "\n",
      "len(df_ins_nudt21_at_flank) = 630\n",
      "len(df_ins_nudt21_at_flank['pas_id'].unique()) = 10\n",
      "len(df_ins_nudt21_at_flank['seq'].unique()) = 630\n",
      "\n",
      "df_ins_nudt21_at_flank['n_bcs'].sum() = 670\n"
     ]
    }
   ],
   "source": [
    "#Load Aim 2.3.3: NUDT21 insertion (AT flank)\n",
    "\n",
    "n_wt = 10\n",
    "n_wt_bcs = 5\n",
    "\n",
    "df_ins_nudt21_at_flank = pd.read_csv(\"samples/epistasis_insert_TGTA_AT_flanks_v2/cell_type_1_ix_0_cell_type_2_ix_6_score_ix_2_n_sequences_10.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "\n",
    "#Select sequence subsets\n",
    "\n",
    "#WT sequences\n",
    "df_ins_nudt21_at_flank_wt = df_ins_nudt21_at_flank.loc[df_ins_nudt21_at_flank['experiment'] == 'wt'].copy().reset_index(drop=True).iloc[:n_wt].copy().reset_index(drop=True)\n",
    "df_ins_nudt21_at_flank_wt['n_bc'] = n_wt_bcs\n",
    "\n",
    "df_ins_nudt21_at_flank = df_ins_nudt21_at_flank.loc[df_ins_nudt21_at_flank['experiment'] != 'wt'].copy().reset_index(drop=True)\n",
    "\n",
    "print(\"len(df_ins_nudt21_at_flank_wt) = \" + str(len(df_ins_nudt21_at_flank_wt)))\n",
    "\n",
    "#Insert one motif\n",
    "df_ins_nudt21_at_flank_insert_1 = df_ins_nudt21_at_flank.loc[~df_ins_nudt21_at_flank['experiment'].str.contains(\"_and_\")].copy().reset_index(drop=True)\n",
    "df_ins_nudt21_at_flank_insert_1['n_bc'] = 1\n",
    "df_ins_nudt21_at_flank_insert_1 = df_ins_nudt21_at_flank_insert_1.loc[df_ins_nudt21_at_flank_insert_1['pas_id'].isin(\n",
    "    df_ins_nudt21_at_flank_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_ins_nudt21_at_flank_insert_1) = \" + str(len(df_ins_nudt21_at_flank_insert_1)))\n",
    "\n",
    "#Insert both motifs\n",
    "df_ins_nudt21_at_flank_insert_1_and_2 = df_ins_nudt21_at_flank.loc[df_ins_nudt21_at_flank['experiment'].str.contains(\"_and_\")].copy().reset_index(drop=True)\n",
    "df_ins_nudt21_at_flank_insert_1_and_2['n_bc'] = 1\n",
    "df_ins_nudt21_at_flank_insert_1_and_2 = df_ins_nudt21_at_flank_insert_1_and_2.loc[df_ins_nudt21_at_flank_insert_1_and_2['pas_id'].isin(\n",
    "    df_ins_nudt21_at_flank_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_ins_nudt21_at_flank_insert_1_and_2) = \" + str(len(df_ins_nudt21_at_flank_insert_1_and_2)))\n",
    "\n",
    "#Concatenate all subexperiment dataframes\n",
    "\n",
    "df_ins_nudt21_at_flank = pd.concat([\n",
    "    df_ins_nudt21_at_flank_wt,\n",
    "    df_ins_nudt21_at_flank_insert_1,\n",
    "    df_ins_nudt21_at_flank_insert_1_and_2,\n",
    "]).copy().reset_index(drop=True)\n",
    "\n",
    "#Append sub-aim metadata column\n",
    "df_ins_nudt21_at_flank['subaim'] = \"at_flank\"\n",
    "\n",
    "print(\"\")\n",
    "print(\"len(df_ins_nudt21_at_flank) = \" + str(len(df_ins_nudt21_at_flank)))\n",
    "print(\"len(df_ins_nudt21_at_flank['pas_id'].unique()) = \" + str(len(df_ins_nudt21_at_flank['pas_id'].unique())))\n",
    "print(\"len(df_ins_nudt21_at_flank['seq'].unique()) = \" + str(len(df_ins_nudt21_at_flank['seq'].unique())))\n",
    "print(\"\")\n",
    "print(\"df_ins_nudt21_at_flank['n_bcs'].sum() = \" + str(int(df_ins_nudt21_at_flank['n_bc'].sum())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_ins_nudt21_gc_flank_wt) = 10\n",
      "len(df_ins_nudt21_gc_flank_insert_1) = 340\n",
      "len(df_ins_nudt21_gc_flank_insert_1_and_2) = 250\n",
      "\n",
      "len(df_ins_nudt21_gc_flank) = 600\n",
      "len(df_ins_nudt21_gc_flank['pas_id'].unique()) = 10\n",
      "len(df_ins_nudt21_gc_flank['seq'].unique()) = 600\n",
      "\n",
      "df_ins_nudt21_gc_flank['n_bcs'].sum() = 640\n"
     ]
    }
   ],
   "source": [
    "#Load Aim 2.3.4: NUDT21 insertion (GC flank)\n",
    "\n",
    "n_wt = 10\n",
    "n_wt_bcs = 5\n",
    "\n",
    "df_ins_nudt21_gc_flank = pd.read_csv(\"samples/epistasis_insert_TGTA_GC_flanks_v2/cell_type_1_ix_0_cell_type_2_ix_6_score_ix_2_n_sequences_10.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "\n",
    "#Select sequence subsets\n",
    "\n",
    "#WT sequences\n",
    "df_ins_nudt21_gc_flank_wt = df_ins_nudt21_gc_flank.loc[df_ins_nudt21_gc_flank['experiment'] == 'wt'].copy().reset_index(drop=True).iloc[:n_wt].copy().reset_index(drop=True)\n",
    "df_ins_nudt21_gc_flank_wt['n_bc'] = n_wt_bcs\n",
    "\n",
    "df_ins_nudt21_gc_flank = df_ins_nudt21_gc_flank.loc[df_ins_nudt21_gc_flank['experiment'] != 'wt'].copy().reset_index(drop=True)\n",
    "\n",
    "print(\"len(df_ins_nudt21_gc_flank_wt) = \" + str(len(df_ins_nudt21_gc_flank_wt)))\n",
    "\n",
    "#Insert one motif\n",
    "df_ins_nudt21_gc_flank_insert_1 = df_ins_nudt21_gc_flank.loc[~df_ins_nudt21_gc_flank['experiment'].str.contains(\"_and_\")].copy().reset_index(drop=True)\n",
    "df_ins_nudt21_gc_flank_insert_1['n_bc'] = 1\n",
    "df_ins_nudt21_gc_flank_insert_1 = df_ins_nudt21_gc_flank_insert_1.loc[df_ins_nudt21_gc_flank_insert_1['pas_id'].isin(\n",
    "    df_ins_nudt21_gc_flank_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_ins_nudt21_gc_flank_insert_1) = \" + str(len(df_ins_nudt21_gc_flank_insert_1)))\n",
    "\n",
    "#Insert both motifs\n",
    "df_ins_nudt21_gc_flank_insert_1_and_2 = df_ins_nudt21_gc_flank.loc[df_ins_nudt21_gc_flank['experiment'].str.contains(\"_and_\")].copy().reset_index(drop=True)\n",
    "df_ins_nudt21_gc_flank_insert_1_and_2['n_bc'] = 1\n",
    "df_ins_nudt21_gc_flank_insert_1_and_2 = df_ins_nudt21_gc_flank_insert_1_and_2.loc[df_ins_nudt21_gc_flank_insert_1_and_2['pas_id'].isin(\n",
    "    df_ins_nudt21_gc_flank_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_ins_nudt21_gc_flank_insert_1_and_2) = \" + str(len(df_ins_nudt21_gc_flank_insert_1_and_2)))\n",
    "\n",
    "#Concatenate all subexperiment dataframes\n",
    "\n",
    "df_ins_nudt21_gc_flank = pd.concat([\n",
    "    df_ins_nudt21_gc_flank_wt,\n",
    "    df_ins_nudt21_gc_flank_insert_1,\n",
    "    df_ins_nudt21_gc_flank_insert_1_and_2,\n",
    "]).copy().reset_index(drop=True)\n",
    "\n",
    "#Append sub-aim metadata column\n",
    "df_ins_nudt21_gc_flank['subaim'] = \"gc_flank\"\n",
    "\n",
    "print(\"\")\n",
    "print(\"len(df_ins_nudt21_gc_flank) = \" + str(len(df_ins_nudt21_gc_flank)))\n",
    "print(\"len(df_ins_nudt21_gc_flank['pas_id'].unique()) = \" + str(len(df_ins_nudt21_gc_flank['pas_id'].unique())))\n",
    "print(\"len(df_ins_nudt21_gc_flank['seq'].unique()) = \" + str(len(df_ins_nudt21_gc_flank['seq'].unique())))\n",
    "print(\"\")\n",
    "print(\"df_ins_nudt21_gc_flank['n_bcs'].sum() = \" + str(int(df_ins_nudt21_gc_flank['n_bc'].sum())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_ins_rbbp6_wt) = 50\n",
      "len(df_ins_rbbp6_insert_1) = 300\n",
      "len(df_ins_rbbp6_insert_1_and_2) = 250\n",
      "\n",
      "len(df_ins_rbbp6) = 600\n",
      "len(df_ins_rbbp6['pas_id'].unique()) = 50\n",
      "len(df_ins_rbbp6['seq'].unique()) = 600\n",
      "\n",
      "df_ins_rbbp6['n_bcs'].sum() = 800\n"
     ]
    }
   ],
   "source": [
    "#Load Aim 2.4: RBBP6 insertion\n",
    "\n",
    "n_wt = 50\n",
    "n_wt_bcs = 5\n",
    "\n",
    "df_ins_rbbp6 = pd.read_csv(\"samples/epistasis_insert_AWTAAA_GT/cell_type_1_ix_0_cell_type_2_ix_7_score_ix_2_n_sequences_50.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "\n",
    "#Select sequence subsets\n",
    "\n",
    "#WT sequences\n",
    "df_ins_rbbp6_wt = df_ins_rbbp6.loc[df_ins_rbbp6['experiment'] == 'wt'].copy().reset_index(drop=True).iloc[:n_wt].copy().reset_index(drop=True)\n",
    "df_ins_rbbp6_wt['n_bc'] = n_wt_bcs\n",
    "\n",
    "df_ins_rbbp6 = df_ins_rbbp6.loc[df_ins_rbbp6['experiment'] != 'wt'].copy().reset_index(drop=True)\n",
    "\n",
    "print(\"len(df_ins_rbbp6_wt) = \" + str(len(df_ins_rbbp6_wt)))\n",
    "\n",
    "#Insert one motif\n",
    "df_ins_rbbp6_insert_1 = df_ins_rbbp6.loc[~df_ins_rbbp6['experiment'].str.contains(\"_and_\")].copy().reset_index(drop=True)\n",
    "df_ins_rbbp6_insert_1['n_bc'] = 1\n",
    "df_ins_rbbp6_insert_1 = df_ins_rbbp6_insert_1.loc[df_ins_rbbp6_insert_1['pas_id'].isin(\n",
    "    df_ins_rbbp6_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_ins_rbbp6_insert_1) = \" + str(len(df_ins_rbbp6_insert_1)))\n",
    "\n",
    "#Insert both motifs\n",
    "df_ins_rbbp6_insert_1_and_2 = df_ins_rbbp6.loc[df_ins_rbbp6['experiment'].str.contains(\"_and_\")].copy().reset_index(drop=True)\n",
    "df_ins_rbbp6_insert_1_and_2['n_bc'] = 1\n",
    "df_ins_rbbp6_insert_1_and_2 = df_ins_rbbp6_insert_1_and_2.loc[df_ins_rbbp6_insert_1_and_2['pas_id'].isin(\n",
    "    df_ins_rbbp6_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "\n",
    "print(\"len(df_ins_rbbp6_insert_1_and_2) = \" + str(len(df_ins_rbbp6_insert_1_and_2)))\n",
    "\n",
    "#Concatenate all subexperiment dataframes\n",
    "\n",
    "df_ins_rbbp6 = pd.concat([\n",
    "    df_ins_rbbp6_wt,\n",
    "    df_ins_rbbp6_insert_1,\n",
    "    df_ins_rbbp6_insert_1_and_2,\n",
    "]).copy().reset_index(drop=True)\n",
    "\n",
    "#Append sub-aim metadata column\n",
    "df_ins_rbbp6['subaim'] = \"no_subaim\"\n",
    "\n",
    "print(\"\")\n",
    "print(\"len(df_ins_rbbp6) = \" + str(len(df_ins_rbbp6)))\n",
    "print(\"len(df_ins_rbbp6['pas_id'].unique()) = \" + str(len(df_ins_rbbp6['pas_id'].unique())))\n",
    "print(\"len(df_ins_rbbp6['seq'].unique()) = \" + str(len(df_ins_rbbp6['seq'].unique())))\n",
    "print(\"\")\n",
    "print(\"df_ins_rbbp6['n_bcs'].sum() = \" + str(int(df_ins_rbbp6['n_bc'].sum())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_module_a_wt) = 50\n",
      "len(df_module_a_mut) = 250\n",
      "\n",
      "len(df_module_a) = 300\n",
      "len(df_module_a['pas_id'].unique()) = 50\n",
      "len(df_module_a['seq'].unique()) = 300\n",
      "\n",
      "df_module_a['n_bcs'].sum() = 500\n"
     ]
    }
   ],
   "source": [
    "#Load Aim 3.1: Module A motif scrambling\n",
    "\n",
    "n_wt_bcs = 5\n",
    "\n",
    "df_module_a = pd.read_csv(\"samples/module_A_or_B_v2/module_A_shuffle_cell_type_1_ix_0_cell_type_2_ix_4_score_ix_0_n_sequences_50_window_size_9.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "\n",
    "#Select sequence subsets\n",
    "\n",
    "#WT sequences\n",
    "df_module_a_wt = df_module_a.loc[df_module_a['experiment'] == 'wt'].copy().reset_index(drop=True)\n",
    "df_module_a_wt['n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_module_a_wt) = \" + str(len(df_module_a_wt)))\n",
    "\n",
    "#Mut sequences\n",
    "df_module_a_mut = df_module_a.loc[df_module_a['experiment'] != 'wt'].copy().reset_index(drop=True)\n",
    "df_module_a_mut['n_bc'] = 1\n",
    "\n",
    "print(\"len(df_module_a_mut) = \" + str(len(df_module_a_mut)))\n",
    "\n",
    "#Concatenate all subexperiment dataframes\n",
    "\n",
    "df_module_a = pd.concat([\n",
    "    df_module_a_wt,\n",
    "    df_module_a_mut,\n",
    "]).copy().reset_index(drop=True)\n",
    "\n",
    "#Append sub-aim metadata column\n",
    "df_module_a['subaim'] = \"module_a\"\n",
    "\n",
    "print(\"\")\n",
    "print(\"len(df_module_a) = \" + str(len(df_module_a)))\n",
    "print(\"len(df_module_a['pas_id'].unique()) = \" + str(len(df_module_a['pas_id'].unique())))\n",
    "print(\"len(df_module_a['seq'].unique()) = \" + str(len(df_module_a['seq'].unique())))\n",
    "print(\"\")\n",
    "print(\"df_module_a['n_bcs'].sum() = \" + str(int(df_module_a['n_bc'].sum())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_module_b_wt) = 50\n",
      "len(df_module_b_mut) = 250\n",
      "\n",
      "len(df_module_b) = 300\n",
      "len(df_module_b['pas_id'].unique()) = 50\n",
      "len(df_module_b['seq'].unique()) = 261\n",
      "\n",
      "df_module_b['n_bcs'].sum() = 500\n"
     ]
    }
   ],
   "source": [
    "#Load Aim 3.2: Module B motif insertion\n",
    "\n",
    "n_wt_bcs = 5\n",
    "\n",
    "df_module_b = pd.read_csv(\"samples/module_A_or_B_v2/module_B_insert_cell_type_1_ix_0_cell_type_2_ix_4_score_ix_0_n_sequences_50_window_size_9.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "\n",
    "#Select sequence subsets\n",
    "\n",
    "#WT sequences\n",
    "df_module_b_wt = df_module_b.loc[df_module_b['experiment'] == 'wt'].copy().reset_index(drop=True)\n",
    "df_module_b_wt['n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_module_b_wt) = \" + str(len(df_module_b_wt)))\n",
    "\n",
    "#Mut sequences\n",
    "df_module_b_mut = df_module_b.loc[df_module_b['experiment'] != 'wt'].copy().reset_index(drop=True)\n",
    "df_module_b_mut['n_bc'] = 1\n",
    "\n",
    "print(\"len(df_module_b_mut) = \" + str(len(df_module_b_mut)))\n",
    "\n",
    "#Concatenate all subexperiment dataframes\n",
    "\n",
    "df_module_b = pd.concat([\n",
    "    df_module_b_wt,\n",
    "    df_module_b_mut,\n",
    "]).copy().reset_index(drop=True)\n",
    "\n",
    "#Append sub-aim metadata column\n",
    "df_module_b['subaim'] = \"module_b\"\n",
    "\n",
    "print(\"\")\n",
    "print(\"len(df_module_b) = \" + str(len(df_module_b)))\n",
    "print(\"len(df_module_b['pas_id'].unique()) = \" + str(len(df_module_b['pas_id'].unique())))\n",
    "print(\"len(df_module_b['seq'].unique()) = \" + str(len(df_module_b['seq'].unique())))\n",
    "print(\"\")\n",
    "print(\"df_module_b['n_bcs'].sum() = \" + str(int(df_module_b['n_bc'].sum())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_improve_nudt21_dist_10) = 55\n",
      "len(df_improve_nudt21_dist_20) = 55\n",
      "len(df_improve_nudt21_prox_10) = 55\n",
      "len(df_improve_nudt21_prox_20) = 55\n",
      "\n",
      "len(df_improve_nudt21) = 220\n",
      "len(df_improve_nudt21['pas_id'].unique()) = 110\n",
      "len(df_improve_nudt21['seq'].unique()) = 220\n",
      "\n",
      "df_improve_nudt21['n_bcs'].sum() = 660\n",
      "-- distal sites --\n",
      "np.mean(hamming_10s) = 10.0\n",
      "np.std(hamming_10s) = 0.0\n",
      "np.mean(hamming_20s) = 20.0\n",
      "np.std(hamming_20s) = 0.0\n",
      "\n",
      "-- proximal sites --\n",
      "np.mean(hamming_10s) = 10.0\n",
      "np.std(hamming_10s) = 0.0\n",
      "np.mean(hamming_20s) = 20.0\n",
      "np.std(hamming_20s) = 0.0\n"
     ]
    }
   ],
   "source": [
    "#Load Aim 4.1: NUDT21 optimization\n",
    "\n",
    "n_seqs = 55\n",
    "\n",
    "n_wt_bcs = 5\n",
    "\n",
    "up_bg = \"\"\n",
    "dn_bg = \"GCATTTTTATTTTGATTTTGATGCTGATGTACCGAAGGGTTGTTTTGTGTTTACGTAGA\"\n",
    "\n",
    "#Distal sequences\n",
    "seqs_nudt21_distal_10 = []\n",
    "with open('samples/perturb_improve_max_score_no_motifs_3000_iters_100_seqs_score_ix_2_ct_1_ix_0_ct_2_ix_6_target_dist_10/intermediate_iter_3000.txt', 'rt') as f :\n",
    "    for line in f.readlines() :\n",
    "        seqs_nudt21_distal_10.append(up_bg + line.strip() + dn_bg)\n",
    "    seqs_nudt21_distal_10 = seqs_nudt21_distal_10[:n_seqs]\n",
    "\n",
    "df_improve_nudt21_dist_10 = df_scramble_nudt21_dist_pos_wt.copy().reset_index(drop=True)\n",
    "df_improve_nudt21_dist_10['seq'] = seqs_nudt21_distal_10\n",
    "df_improve_nudt21_dist_10['n_bc'] = 3\n",
    "df_improve_nudt21_dist_10['experiment'] = \"improve_10\"\n",
    "\n",
    "print(\"len(df_improve_nudt21_dist_10) = \" + str(len(df_improve_nudt21_dist_10)))\n",
    "\n",
    "seqs_nudt21_distal_20 = []\n",
    "with open('samples/perturb_improve_max_score_no_motifs_3000_iters_100_seqs_score_ix_2_ct_1_ix_0_ct_2_ix_6_target_dist_20/intermediate_iter_3000.txt', 'rt') as f :\n",
    "    for line in f.readlines() :\n",
    "        seqs_nudt21_distal_20.append(up_bg + line.strip() + dn_bg)\n",
    "    seqs_nudt21_distal_20 = seqs_nudt21_distal_20[:n_seqs]\n",
    "\n",
    "df_improve_nudt21_dist_20 = df_scramble_nudt21_dist_pos_wt.copy().reset_index(drop=True)\n",
    "df_improve_nudt21_dist_20['seq'] = seqs_nudt21_distal_20\n",
    "df_improve_nudt21_dist_20['n_bc'] = 3\n",
    "df_improve_nudt21_dist_20['experiment'] = \"improve_20\"\n",
    "\n",
    "print(\"len(df_improve_nudt21_dist_20) = \" + str(len(df_improve_nudt21_dist_20)))\n",
    "\n",
    "#Proximal sequences\n",
    "seqs_nudt21_proximal_10 = []\n",
    "with open('samples/perturb_improve_max_score_no_motifs_3000_iters_100_seqs_score_ix_0_ct_1_ix_0_ct_2_ix_6_target_dist_10/intermediate_iter_3000.txt', 'rt') as f :\n",
    "    for line in f.readlines() :\n",
    "        seqs_nudt21_proximal_10.append(up_bg + line.strip() + dn_bg)\n",
    "    seqs_nudt21_proximal_10 = seqs_nudt21_proximal_10[:n_seqs]\n",
    "\n",
    "df_improve_nudt21_prox_10 = df_scramble_nudt21_prox_pos_wt.copy().reset_index(drop=True)\n",
    "df_improve_nudt21_prox_10['seq'] = seqs_nudt21_proximal_10\n",
    "df_improve_nudt21_prox_10['n_bc'] = 3\n",
    "df_improve_nudt21_prox_10['experiment'] = \"improve_10\"\n",
    "\n",
    "print(\"len(df_improve_nudt21_prox_10) = \" + str(len(df_improve_nudt21_prox_10)))\n",
    "\n",
    "seqs_nudt21_proximal_20 = []\n",
    "with open('samples/perturb_improve_max_score_no_motifs_3000_iters_100_seqs_score_ix_0_ct_1_ix_0_ct_2_ix_6_target_dist_20/intermediate_iter_3000.txt', 'rt') as f :\n",
    "    for line in f.readlines() :\n",
    "        seqs_nudt21_proximal_20.append(up_bg + line.strip() + dn_bg)\n",
    "    seqs_nudt21_proximal_20 = seqs_nudt21_proximal_20[:n_seqs]\n",
    "\n",
    "df_improve_nudt21_prox_20 = df_scramble_nudt21_prox_pos_wt.copy().reset_index(drop=True)\n",
    "df_improve_nudt21_prox_20['seq'] = seqs_nudt21_proximal_20\n",
    "df_improve_nudt21_prox_20['n_bc'] = 3\n",
    "df_improve_nudt21_prox_20['experiment'] = \"improve_20\"\n",
    "\n",
    "print(\"len(df_improve_nudt21_prox_20) = \" + str(len(df_improve_nudt21_prox_20)))\n",
    "\n",
    "#Concatenate all subexperiment dataframes\n",
    "\n",
    "df_improve_nudt21 = pd.concat([\n",
    "    df_improve_nudt21_dist_10,\n",
    "    df_improve_nudt21_dist_20,\n",
    "    df_improve_nudt21_prox_10,\n",
    "    df_improve_nudt21_prox_20,\n",
    "]).copy().reset_index(drop=True)\n",
    "\n",
    "#Append sub-aim metadata column\n",
    "df_improve_nudt21['subaim'] = \"improve_nudt21\"\n",
    "\n",
    "print(\"\")\n",
    "print(\"len(df_improve_nudt21) = \" + str(len(df_improve_nudt21)))\n",
    "print(\"len(df_improve_nudt21['pas_id'].unique()) = \" + str(len(df_improve_nudt21['pas_id'].unique())))\n",
    "print(\"len(df_improve_nudt21['seq'].unique()) = \" + str(len(df_improve_nudt21['seq'].unique())))\n",
    "print(\"\")\n",
    "print(\"df_improve_nudt21['n_bcs'].sum() = \" + str(int(df_improve_nudt21['n_bc'].sum())))\n",
    "\n",
    "#Verify hamming distance to matched wt sequences (dist)\n",
    "\n",
    "hamming_10s = []\n",
    "hamming_20s = []\n",
    "for [_, row_wt], [_, row_10], [_, row_20] in zip(df_scramble_nudt21_dist_pos_wt.iterrows(), df_improve_nudt21_dist_10.iterrows(), df_improve_nudt21_dist_20.iterrows()) :\n",
    "    \n",
    "    hamming_10 = 0\n",
    "    for j in range(0, 70) :\n",
    "        if row_wt['seq'][j] != row_10['seq'][j] :\n",
    "            hamming_10 += 1\n",
    "    \n",
    "    hamming_10s.append(hamming_10)\n",
    "    \n",
    "    hamming_20 = 0\n",
    "    for j in range(0, 70) :\n",
    "        if row_wt['seq'][j] != row_20['seq'][j] :\n",
    "            hamming_20 += 1\n",
    "    \n",
    "    hamming_20s.append(hamming_20)\n",
    "\n",
    "print(\"-- distal sites --\")\n",
    "print(\"np.mean(hamming_10s) = \" + str(np.mean(hamming_10s)))\n",
    "print(\"np.std(hamming_10s) = \" + str(np.std(hamming_10s)))\n",
    "print(\"np.mean(hamming_20s) = \" + str(np.mean(hamming_20s)))\n",
    "print(\"np.std(hamming_20s) = \" + str(np.std(hamming_20s)))\n",
    "print(\"\")\n",
    "\n",
    "#Verify hamming distance to matched wt sequences (prox)\n",
    "\n",
    "hamming_10s = []\n",
    "hamming_20s = []\n",
    "for [_, row_wt], [_, row_10], [_, row_20] in zip(df_scramble_nudt21_prox_pos_wt.iterrows(), df_improve_nudt21_prox_10.iterrows(), df_improve_nudt21_prox_20.iterrows()) :\n",
    "    \n",
    "    hamming_10 = 0\n",
    "    for j in range(0, 70) :\n",
    "        if row_wt['seq'][j] != row_10['seq'][j] :\n",
    "            hamming_10 += 1\n",
    "    \n",
    "    hamming_10s.append(hamming_10)\n",
    "    \n",
    "    hamming_20 = 0\n",
    "    for j in range(0, 70) :\n",
    "        if row_wt['seq'][j] != row_20['seq'][j] :\n",
    "            hamming_20 += 1\n",
    "    \n",
    "    hamming_20s.append(hamming_20)\n",
    "\n",
    "print(\"-- proximal sites --\")\n",
    "print(\"np.mean(hamming_10s) = \" + str(np.mean(hamming_10s)))\n",
    "print(\"np.std(hamming_10s) = \" + str(np.std(hamming_10s)))\n",
    "print(\"np.mean(hamming_20s) = \" + str(np.mean(hamming_20s)))\n",
    "print(\"np.std(hamming_20s) = \" + str(np.std(hamming_20s)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_improve_cstf3_dist_10) = 55\n",
      "len(df_improve_cstf3_dist_20) = 55\n",
      "len(df_improve_cstf3_prox_10) = 55\n",
      "len(df_improve_cstf3_prox_20) = 55\n",
      "\n",
      "len(df_improve_cstf3) = 220\n",
      "len(df_improve_cstf3['pas_id'].unique()) = 110\n",
      "len(df_improve_cstf3['seq'].unique()) = 220\n",
      "\n",
      "df_improve_cstf3['n_bcs'].sum() = 660\n",
      "-- distal sites --\n",
      "np.mean(hamming_10s) = 10.0\n",
      "np.std(hamming_10s) = 0.0\n",
      "np.mean(hamming_20s) = 19.98181818181818\n",
      "np.std(hamming_20s) = 0.13360853142453696\n",
      "\n",
      "-- proximal sites --\n",
      "np.mean(hamming_10s) = 9.981818181818182\n",
      "np.std(hamming_10s) = 0.133608531424537\n",
      "np.mean(hamming_20s) = 19.98181818181818\n",
      "np.std(hamming_20s) = 0.13360853142453696\n"
     ]
    }
   ],
   "source": [
    "#Load Aim 4.2: CSTF3 optimization\n",
    "\n",
    "n_seqs = 55\n",
    "\n",
    "n_wt_bcs = 5\n",
    "\n",
    "up_bg = \"\"\n",
    "dn_bg = \"GCATTTTTATTTTGATTTTGATGCTGATGTACCGAAGGGTTGTTTTGTGTTTACGTAGA\"\n",
    "\n",
    "#Distal sequences\n",
    "seqs_cstf3_distal_10 = []\n",
    "with open('samples/perturb_improve_max_score_no_motifs_3000_iters_100_seqs_score_ix_2_ct_1_ix_0_ct_2_ix_4_target_dist_10/intermediate_iter_3000.txt', 'rt') as f :\n",
    "    for line in f.readlines() :\n",
    "        seqs_cstf3_distal_10.append(up_bg + line.strip() + dn_bg)\n",
    "    seqs_cstf3_distal_10 = seqs_cstf3_distal_10[:n_seqs]\n",
    "\n",
    "df_improve_cstf3_dist_10 = df_scramble_cstf3_dist_pos_wt.copy().reset_index(drop=True)\n",
    "df_improve_cstf3_dist_10['seq'] = seqs_cstf3_distal_10\n",
    "df_improve_cstf3_dist_10['n_bc'] = 3\n",
    "df_improve_cstf3_dist_10['experiment'] = \"improve_10\"\n",
    "\n",
    "print(\"len(df_improve_cstf3_dist_10) = \" + str(len(df_improve_cstf3_dist_10)))\n",
    "\n",
    "seqs_cstf3_distal_20 = []\n",
    "with open('samples/perturb_improve_max_score_no_motifs_3000_iters_100_seqs_score_ix_2_ct_1_ix_0_ct_2_ix_4_target_dist_20/intermediate_iter_3000.txt', 'rt') as f :\n",
    "    for line in f.readlines() :\n",
    "        seqs_cstf3_distal_20.append(up_bg + line.strip() + dn_bg)\n",
    "    seqs_cstf3_distal_20 = seqs_cstf3_distal_20[:n_seqs]\n",
    "\n",
    "df_improve_cstf3_dist_20 = df_scramble_cstf3_dist_pos_wt.copy().reset_index(drop=True)\n",
    "df_improve_cstf3_dist_20['seq'] = seqs_cstf3_distal_20\n",
    "df_improve_cstf3_dist_20['n_bc'] = 3\n",
    "df_improve_cstf3_dist_20['experiment'] = \"improve_20\"\n",
    "\n",
    "print(\"len(df_improve_cstf3_dist_20) = \" + str(len(df_improve_cstf3_dist_20)))\n",
    "\n",
    "#Proximal sequences\n",
    "seqs_cstf3_proximal_10 = []\n",
    "with open('samples/perturb_improve_max_score_no_motifs_3000_iters_100_seqs_score_ix_0_ct_1_ix_0_ct_2_ix_4_target_dist_10/intermediate_iter_3000.txt', 'rt') as f :\n",
    "    for line in f.readlines() :\n",
    "        seqs_cstf3_proximal_10.append(up_bg + line.strip() + dn_bg)\n",
    "    seqs_cstf3_proximal_10 = seqs_cstf3_proximal_10[:n_seqs]\n",
    "\n",
    "df_improve_cstf3_prox_10 = df_scramble_cstf3_prox_pos_wt.copy().reset_index(drop=True)\n",
    "df_improve_cstf3_prox_10['seq'] = seqs_cstf3_proximal_10\n",
    "df_improve_cstf3_prox_10['n_bc'] = 3\n",
    "df_improve_cstf3_prox_10['experiment'] = \"improve_10\"\n",
    "\n",
    "print(\"len(df_improve_cstf3_prox_10) = \" + str(len(df_improve_cstf3_prox_10)))\n",
    "\n",
    "seqs_cstf3_proximal_20 = []\n",
    "with open('samples/perturb_improve_max_score_no_motifs_3000_iters_100_seqs_score_ix_0_ct_1_ix_0_ct_2_ix_4_target_dist_20/intermediate_iter_3000.txt', 'rt') as f :\n",
    "    for line in f.readlines() :\n",
    "        seqs_cstf3_proximal_20.append(up_bg + line.strip() + dn_bg)\n",
    "    seqs_cstf3_proximal_20 = seqs_cstf3_proximal_20[:n_seqs]\n",
    "\n",
    "df_improve_cstf3_prox_20 = df_scramble_cstf3_prox_pos_wt.copy().reset_index(drop=True)\n",
    "df_improve_cstf3_prox_20['seq'] = seqs_cstf3_proximal_20\n",
    "df_improve_cstf3_prox_20['n_bc'] = 3\n",
    "df_improve_cstf3_prox_20['experiment'] = \"improve_20\"\n",
    "\n",
    "print(\"len(df_improve_cstf3_prox_20) = \" + str(len(df_improve_cstf3_prox_20)))\n",
    "\n",
    "#Concatenate all subexperiment dataframes\n",
    "\n",
    "df_improve_cstf3 = pd.concat([\n",
    "    df_improve_cstf3_dist_10,\n",
    "    df_improve_cstf3_dist_20,\n",
    "    df_improve_cstf3_prox_10,\n",
    "    df_improve_cstf3_prox_20,\n",
    "]).copy().reset_index(drop=True)\n",
    "\n",
    "#Append sub-aim metadata column\n",
    "df_improve_cstf3['subaim'] = \"improve_cstf3\"\n",
    "\n",
    "print(\"\")\n",
    "print(\"len(df_improve_cstf3) = \" + str(len(df_improve_cstf3)))\n",
    "print(\"len(df_improve_cstf3['pas_id'].unique()) = \" + str(len(df_improve_cstf3['pas_id'].unique())))\n",
    "print(\"len(df_improve_cstf3['seq'].unique()) = \" + str(len(df_improve_cstf3['seq'].unique())))\n",
    "print(\"\")\n",
    "print(\"df_improve_cstf3['n_bcs'].sum() = \" + str(int(df_improve_cstf3['n_bc'].sum())))\n",
    "\n",
    "#Verify hamming distance to matched wt sequences (dist)\n",
    "\n",
    "hamming_10s = []\n",
    "hamming_20s = []\n",
    "for [_, row_wt], [_, row_10], [_, row_20] in zip(df_scramble_cstf3_dist_pos_wt.iterrows(), df_improve_cstf3_dist_10.iterrows(), df_improve_cstf3_dist_20.iterrows()) :\n",
    "    \n",
    "    hamming_10 = 0\n",
    "    for j in range(76, 146) :\n",
    "        if row_wt['seq'][j] != row_10['seq'][j] :\n",
    "            hamming_10 += 1\n",
    "    \n",
    "    hamming_10s.append(hamming_10)\n",
    "    \n",
    "    hamming_20 = 0\n",
    "    for j in range(76, 146) :\n",
    "        if row_wt['seq'][j] != row_20['seq'][j] :\n",
    "            hamming_20 += 1\n",
    "    \n",
    "    hamming_20s.append(hamming_20)\n",
    "\n",
    "print(\"-- distal sites --\")\n",
    "print(\"np.mean(hamming_10s) = \" + str(np.mean(hamming_10s)))\n",
    "print(\"np.std(hamming_10s) = \" + str(np.std(hamming_10s)))\n",
    "print(\"np.mean(hamming_20s) = \" + str(np.mean(hamming_20s)))\n",
    "print(\"np.std(hamming_20s) = \" + str(np.std(hamming_20s)))\n",
    "print(\"\")\n",
    "\n",
    "#Verify hamming distance to matched wt sequences (prox)\n",
    "\n",
    "hamming_10s = []\n",
    "hamming_20s = []\n",
    "for [_, row_wt], [_, row_10], [_, row_20] in zip(df_scramble_cstf3_prox_pos_wt.iterrows(), df_improve_cstf3_prox_10.iterrows(), df_improve_cstf3_prox_20.iterrows()) :\n",
    "    \n",
    "    hamming_10 = 0\n",
    "    for j in range(76, 146) :\n",
    "        if row_wt['seq'][j] != row_10['seq'][j] :\n",
    "            hamming_10 += 1\n",
    "    \n",
    "    hamming_10s.append(hamming_10)\n",
    "    \n",
    "    hamming_20 = 0\n",
    "    for j in range(76, 146) :\n",
    "        if row_wt['seq'][j] != row_20['seq'][j] :\n",
    "            hamming_20 += 1\n",
    "    \n",
    "    hamming_20s.append(hamming_20)\n",
    "\n",
    "print(\"-- proximal sites --\")\n",
    "print(\"np.mean(hamming_10s) = \" + str(np.mean(hamming_10s)))\n",
    "print(\"np.std(hamming_10s) = \" + str(np.std(hamming_10s)))\n",
    "print(\"np.mean(hamming_20s) = \" + str(np.mean(hamming_20s)))\n",
    "print(\"np.std(hamming_20s) = \" + str(np.std(hamming_20s)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_cse_prox_wt) = 10\n",
      "len(df_cse_dist_wt) = 10\n",
      "len(df_cse_prox_mut) = 190\n",
      "len(df_cse_dist_mut) = 190\n",
      "\n",
      "len(df_cse) = 400\n",
      "len(df_cse['pas_id'].unique()) = 20\n",
      "len(df_cse['seq'].unique()) = 400\n",
      "\n",
      "df_cse['n_bcs'].sum() = 1200\n"
     ]
    }
   ],
   "source": [
    "#Load Aim 5: Core hexamer variants\n",
    "\n",
    "n_wt = 10\n",
    "n_wt_bcs = 3\n",
    "\n",
    "df_cse_prox = pd.read_csv(\"samples/unif_wt_score_ix_0/apa_perturb_v3_score_ix_0_n_sequences_50_cse.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "df_cse_dist = pd.read_csv(\"samples/unif_wt_score_ix_2/apa_perturb_v3_score_ix_2_n_sequences_50_cse.txt\", sep='\\t')[['gene_id', 'pas_id', 'experiment', 'seq']]\n",
    "\n",
    "#Select sequence subsets\n",
    "\n",
    "#WT sequences\n",
    "df_cse_prox_wt = df_cse_prox.loc[df_cse_prox['experiment'] == 'wt'].copy().reset_index(drop=True).iloc[:n_wt].copy().reset_index(drop=True)\n",
    "df_cse_prox_wt['n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_cse_prox_wt) = \" + str(len(df_cse_prox_wt)))\n",
    "\n",
    "df_cse_dist_wt = df_cse_dist.loc[df_cse_dist['experiment'] == 'wt'].copy().reset_index(drop=True).iloc[:n_wt].copy().reset_index(drop=True)\n",
    "df_cse_dist_wt['n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_cse_dist_wt) = \" + str(len(df_cse_dist_wt)))\n",
    "\n",
    "#Replaced CSEs\n",
    "df_cse_prox_mut = df_cse_prox.loc[df_cse_prox['experiment'].str.contains(\"replace_cse\")].copy().reset_index(drop=True)\n",
    "df_cse_prox_mut['n_bc'] = 1\n",
    "df_cse_prox_mut = df_cse_prox_mut.loc[df_cse_prox_mut['pas_id'].isin(\n",
    "    df_cse_prox_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "df_cse_prox_mut['n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_cse_prox_mut) = \" + str(len(df_cse_prox_mut)))\n",
    "\n",
    "df_cse_dist_mut = df_cse_dist.loc[df_cse_dist['experiment'].str.contains(\"replace_cse\")].copy().reset_index(drop=True)\n",
    "df_cse_dist_mut['n_bc'] = 1\n",
    "df_cse_dist_mut = df_cse_dist_mut.loc[df_cse_dist_mut['pas_id'].isin(\n",
    "    df_cse_dist_wt['pas_id'].values.tolist()\n",
    ")]\n",
    "df_cse_dist_mut['n_bc'] = n_wt_bcs\n",
    "\n",
    "print(\"len(df_cse_dist_mut) = \" + str(len(df_cse_dist_mut)))\n",
    "\n",
    "#Append sub-aim metadata column\n",
    "df_cse_prox_wt['subaim'] = \"proximal\"\n",
    "df_cse_prox_mut['subaim'] = \"proximal\"\n",
    "df_cse_dist_wt['subaim'] = \"distal\"\n",
    "df_cse_dist_mut['subaim'] = \"distal\"\n",
    "\n",
    "#Concatenate all subexperiment dataframes\n",
    "\n",
    "df_cse = pd.concat([\n",
    "    df_cse_prox_wt,\n",
    "    df_cse_prox_mut,\n",
    "    df_cse_dist_wt,\n",
    "    df_cse_dist_mut,\n",
    "]).copy().reset_index(drop=True)\n",
    "\n",
    "print(\"\")\n",
    "print(\"len(df_cse) = \" + str(len(df_cse)))\n",
    "print(\"len(df_cse['pas_id'].unique()) = \" + str(len(df_cse['pas_id'].unique())))\n",
    "print(\"len(df_cse['seq'].unique()) = \" + str(len(df_cse['seq'].unique())))\n",
    "print(\"\")\n",
    "print(\"df_cse['n_bcs'].sum() = \" + str(int(df_cse['n_bc'].sum())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "len(gwas_df) = 838\n",
      "len(gwas_df['pas_id'].unique()) = 419\n",
      "len(gwas_df['seq'].unique()) = 838\n",
      "\n",
      "gwas_df['n_bcs'].sum() = 2514\n"
     ]
    }
   ],
   "source": [
    "#Load Aim 6.1: GWAS variants\n",
    "\n",
    "gwas_df = pd.read_csv(\"samples/gwas_ukbb_and_causaldb_20230517_pip_020.csv\", sep='\\t')[['gene', 'snp_id', 'ref_seq', 'var_seq']]\n",
    "\n",
    "gwas_df_ref = gwas_df[['gene', 'snp_id', 'ref_seq']].copy().reset_index(drop=True)\n",
    "gwas_df_var = gwas_df[['gene', 'snp_id', 'var_seq']].copy().reset_index(drop=True)\n",
    "\n",
    "gwas_df_ref['experiment'] = 'ref'\n",
    "gwas_df_var['experiment'] = 'var'\n",
    "\n",
    "gwas_df_ref = gwas_df_ref.rename(columns={\n",
    "    'gene' : 'gene_id',\n",
    "    'snp_id' : 'pas_id',\n",
    "    'ref_seq' : 'seq',\n",
    "})\n",
    "\n",
    "gwas_df_var = gwas_df_var.rename(columns={\n",
    "    'gene' : 'gene_id',\n",
    "    'snp_id' : 'pas_id',\n",
    "    'var_seq' : 'seq',\n",
    "})\n",
    "\n",
    "gwas_df_ref['n_bc'] = 3\n",
    "gwas_df_var['n_bc'] = 3\n",
    "\n",
    "gwas_df_ref = gwas_df_ref[['gene_id', 'pas_id', 'experiment', 'seq', 'n_bc']]\n",
    "gwas_df_var = gwas_df_var[['gene_id', 'pas_id', 'experiment', 'seq', 'n_bc']]\n",
    "\n",
    "gwas_df = pd.concat([\n",
    "    gwas_df_ref,\n",
    "    gwas_df_var,\n",
    "]).copy().reset_index(drop=True)\n",
    "\n",
    "#Append sub-aim metadata column\n",
    "gwas_df['subaim'] = \"gwas\"\n",
    "\n",
    "print(\"\")\n",
    "print(\"len(gwas_df) = \" + str(len(gwas_df)))\n",
    "print(\"len(gwas_df['pas_id'].unique()) = \" + str(len(gwas_df['pas_id'].unique())))\n",
    "print(\"len(gwas_df['seq'].unique()) = \" + str(len(gwas_df['seq'].unique())))\n",
    "print(\"\")\n",
    "print(\"gwas_df['n_bcs'].sum() = \" + str(int(gwas_df['n_bc'].sum())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "len(clinvar_df) = 762\n",
      "len(clinvar_df['pas_id'].unique()) = 369\n",
      "len(clinvar_df['seq'].unique()) = 697\n",
      "\n",
      "clinvar_df['n_bcs'].sum() = 2286\n"
     ]
    }
   ],
   "source": [
    "#Load Aim 6.2: Clinically relevant variants\n",
    "\n",
    "clinvar_df = pd.read_csv(\"samples/clinvar_variants_20230517.csv\", sep='\\t')[['gene', 'clinvar_id', 'ref_seq', 'var_seq']]\n",
    "\n",
    "clinvar_df_ref = clinvar_df[['gene', 'clinvar_id', 'ref_seq']].copy().reset_index(drop=True)\n",
    "clinvar_df_var = clinvar_df[['gene', 'clinvar_id', 'var_seq']].copy().reset_index(drop=True)\n",
    "\n",
    "clinvar_df_ref['experiment'] = 'ref'\n",
    "clinvar_df_var['experiment'] = 'var'\n",
    "\n",
    "clinvar_df_ref = clinvar_df_ref.rename(columns={\n",
    "    'gene' : 'gene_id',\n",
    "    'clinvar_id' : 'pas_id',\n",
    "    'ref_seq' : 'seq',\n",
    "})\n",
    "\n",
    "clinvar_df_var = clinvar_df_var.rename(columns={\n",
    "    'gene' : 'gene_id',\n",
    "    'clinvar_id' : 'pas_id',\n",
    "    'var_seq' : 'seq',\n",
    "})\n",
    "\n",
    "clinvar_df_ref['n_bc'] = 3\n",
    "clinvar_df_var['n_bc'] = 3\n",
    "\n",
    "clinvar_df_ref = clinvar_df_ref[['gene_id', 'pas_id', 'experiment', 'seq', 'n_bc']]\n",
    "clinvar_df_var = clinvar_df_var[['gene_id', 'pas_id', 'experiment', 'seq', 'n_bc']]\n",
    "\n",
    "clinvar_df = pd.concat([\n",
    "    clinvar_df_ref,\n",
    "    clinvar_df_var,\n",
    "]).copy().reset_index(drop=True)\n",
    "\n",
    "#Append sub-aim metadata column\n",
    "clinvar_df['subaim'] = \"clinvar\"\n",
    "\n",
    "print(\"\")\n",
    "print(\"len(clinvar_df) = \" + str(len(clinvar_df)))\n",
    "print(\"len(clinvar_df['pas_id'].unique()) = \" + str(len(clinvar_df['pas_id'].unique())))\n",
    "print(\"len(clinvar_df['seq'].unique()) = \" + str(len(clinvar_df['seq'].unique())))\n",
    "print(\"\")\n",
    "print(\"clinvar_df['n_bcs'].sum() = \" + str(int(clinvar_df['n_bc'].sum())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(library_df) = 15005 (before filtering)\n",
      "\n",
      "% of library with restricted 6-mer(s) = 2.47%\n",
      "\n",
      "-- # wt seqs / aim matching restricted 6-mer(s) --\n",
      "aim_1_1_scramble_nudt21 = 5\n",
      "aim_1_2_scramble_cstf3 = 4\n",
      "aim_1_3_scramble_rbbp6 = 5\n",
      "aim_2_1_ablate_nudt21 = 1\n",
      "aim_2_2_ablate_rbbp6 = 1\n",
      "aim_2_3_insert_nudt21 = 1\n",
      "aim_3_1_module_a = 1\n",
      "aim_3_2_module_b = 3\n",
      "aim_5_substitute_hexamer = 1\n",
      "aim_6_variants = 22\n",
      "\n",
      "-- # wt seqs / aim after filtering --\n",
      "aim_1_1_scramble_nudt21 = 215\n",
      "aim_1_2_scramble_cstf3 = 216\n",
      "aim_1_3_scramble_rbbp6 = 105\n",
      "aim_2_1_ablate_nudt21 = 89\n",
      "aim_2_2_ablate_rbbp6 = 49\n",
      "aim_2_3_insert_nudt21 = 39\n",
      "aim_2_4_insert_rbbp6 = 50\n",
      "aim_3_1_module_a = 49\n",
      "aim_3_2_module_b = 47\n",
      "aim_4_improve = 214\n",
      "aim_5_substitute_hexamer = 19\n",
      "aim_6_variants = 778\n",
      "\n",
      "len(library_df) = 14625 (after filtering)\n",
      "\n",
      "len(library_df) = 14487 (after dropping duplicates)\n",
      "\n",
      "library_df['n_bcs'].sum() = 23241\n"
     ]
    }
   ],
   "source": [
    "#Compile final library file (not barcoded)\n",
    "\n",
    "#Append metadata column(s)\n",
    "\n",
    "#Aim 1\n",
    "df_scramble_nudt21['aim'] = 'aim_1_1_scramble_nudt21'\n",
    "df_scramble_cstf3['aim']  = 'aim_1_2_scramble_cstf3'\n",
    "df_scramble_rbbp6['aim']  = 'aim_1_3_scramble_rbbp6'\n",
    "\n",
    "#Aim 2\n",
    "df_abl_nudt21_at['aim']       = \"aim_2_1_ablate_nudt21\"\n",
    "df_abl_nudt21_gc['aim']       = \"aim_2_1_ablate_nudt21\"\n",
    "df_abl_rbbp6['aim']           = \"aim_2_2_ablate_rbbp6\"\n",
    "df_ins_nudt21_at_comp['aim']  = \"aim_2_3_insert_nudt21\"\n",
    "df_ins_nudt21_gc_comp['aim']  = \"aim_2_3_insert_nudt21\"\n",
    "df_ins_nudt21_at_flank['aim'] = \"aim_2_3_insert_nudt21\"\n",
    "df_ins_nudt21_gc_flank['aim'] = \"aim_2_3_insert_nudt21\"\n",
    "df_ins_rbbp6['aim']           = \"aim_2_4_insert_rbbp6\"\n",
    "\n",
    "#Aim 3\n",
    "df_module_a['aim'] = \"aim_3_1_module_a\"\n",
    "df_module_b['aim'] = \"aim_3_2_module_b\"\n",
    "\n",
    "#Aim 4\n",
    "df_improve_nudt21['aim'] = \"aim_4_improve\"\n",
    "df_improve_cstf3['aim'] = \"aim_4_improve\"\n",
    "\n",
    "#Aim 5\n",
    "df_cse['aim'] = \"aim_5_substitute_hexamer\"\n",
    "\n",
    "#Aim 6\n",
    "gwas_df['aim'] = \"aim_6_variants\"\n",
    "clinvar_df['aim'] = \"aim_6_variants\"\n",
    "\n",
    "library_df = pd.concat([\n",
    "    #Aim 1\n",
    "    df_scramble_nudt21,\n",
    "    df_scramble_cstf3,\n",
    "    df_scramble_rbbp6,\n",
    "    \n",
    "    #Aim 2\n",
    "    df_abl_nudt21_at,\n",
    "    df_abl_nudt21_gc,\n",
    "    df_abl_rbbp6,\n",
    "    df_ins_nudt21_at_comp,\n",
    "    df_ins_nudt21_gc_comp,\n",
    "    df_ins_nudt21_at_flank,\n",
    "    df_ins_nudt21_gc_flank,\n",
    "    df_ins_rbbp6,\n",
    "    \n",
    "    #Aim 3\n",
    "    df_module_a,\n",
    "    df_module_b,\n",
    "    \n",
    "    #Aim 4\n",
    "    df_improve_nudt21,\n",
    "    df_improve_cstf3,\n",
    "\n",
    "    #Aim 5\n",
    "    df_cse,\n",
    "    \n",
    "    #Aim 6\n",
    "    gwas_df,\n",
    "    clinvar_df,\n",
    "]).copy().reset_index(drop=True)\n",
    "\n",
    "print(\"len(library_df) = \" + str(len(library_df)) + \" (before filtering)\")\n",
    "print(\"\")\n",
    "\n",
    "#Mark sequences that match restricted 6-mers\n",
    "library_df['has_restricted_6mer'] = library_df['seq'].str.contains(\"GAGACG|CGTCTC\")\n",
    "\n",
    "n_total = len(library_df)\n",
    "n_faulty = len(library_df.query(\"has_restricted_6mer == True\"))\n",
    "\n",
    "print(\"% of library with restricted 6-mer(s) = \" + str(round(100. * (n_faulty / n_total), 2)) + \"%\")\n",
    "print(\"\")\n",
    "\n",
    "#Print statistics of aims that match restricted 6-mer\n",
    "aims, aim_counts = np.unique(np.array(library_df.query(\"has_restricted_6mer == True and (experiment == 'wt' or experiment == 'ref')\")['aim'].values, dtype=object), return_counts=True)\n",
    "\n",
    "print(\"-- # wt seqs / aim matching restricted 6-mer(s) --\")\n",
    "for aim, aim_c in zip(aims.tolist(), aim_counts.tolist()) :\n",
    "    print(aim + \" = \" + str(aim_c))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "#Remove sequences matching restricted 6-mers\n",
    "library_df = library_df.query(\"has_restricted_6mer == False\").copy().reset_index(drop=True)\n",
    "\n",
    "#Remove sequences that lost their WT\n",
    "wt_pas_ids = sorted(library_df.query(\"experiment == 'wt'\")['pas_id'].unique().tolist())\n",
    "\n",
    "library_df = library_df.loc[\n",
    "    library_df['aim'].isin([\"aim_6_variants\"]) |\n",
    "    library_df['pas_id'].isin(wt_pas_ids)\n",
    "].copy().reset_index(drop=True)\n",
    "\n",
    "#Print statistics of aims after filtering\n",
    "aims, aim_counts = np.unique(np.array(library_df.query(\"experiment == 'wt' or experiment == 'ref' or (aim == 'aim_4_improve' and experiment == 'improve_10')\")['aim'].values, dtype=object), return_counts=True)\n",
    "\n",
    "print(\"-- # wt seqs / aim after filtering --\")\n",
    "for aim, aim_c in zip(aims.tolist(), aim_counts.tolist()) :\n",
    "    print(aim + \" = \" + str(aim_c))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"len(library_df) = \" + str(len(library_df)) + \" (after filtering)\")\n",
    "print(\"\")\n",
    "\n",
    "#Drop duplicate sequences\n",
    "library_df = library_df.drop_duplicates(subset=['seq'], keep='first').copy().reset_index(drop=True)\n",
    "\n",
    "print(\"len(library_df) = \" + str(len(library_df)) + \" (after dropping duplicates)\")\n",
    "print(\"\")\n",
    "print(\"library_df['n_bcs'].sum() = \" + str(int(library_df['n_bc'].sum())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_id</th>\n",
       "      <th>pas_id</th>\n",
       "      <th>experiment</th>\n",
       "      <th>seq</th>\n",
       "      <th>n_bc</th>\n",
       "      <th>subaim</th>\n",
       "      <th>aim</th>\n",
       "      <th>has_restricted_6mer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [gene_id, pas_id, experiment, seq, n_bc, subaim, aim, has_restricted_6mer]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check that there are no more restricted 6-mer hits\n",
    "\n",
    "library_df.query(\"has_restricted_6mer == True\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save final library file (not barcoded)\n",
    "\n",
    "library_df.to_csv(\"apa_perturb_mpra_v1_top_module_A_and_B.csv\", sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
