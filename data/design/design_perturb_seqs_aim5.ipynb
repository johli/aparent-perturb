{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2023-05-09 15:40:56.489154: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "'''\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "def contain_tf_gpu_mem_usage() :\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "    set_session(sess)\n",
    "\n",
    "contain_tf_gpu_mem_usage()\n",
    "'''\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "#import seaborn as sns\n",
    "\n",
    "import urllib\n",
    "import urllib.request\n",
    "import pickle\n",
    "from time import sleep\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import h5py\n",
    "\n",
    "#Visualization code\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "def ic_scale(pwm,background):\n",
    "    per_position_ic = util.compute_per_position_ic(\n",
    "                       ppm=pwm, background=background, pseudocount=0.001)\n",
    "    return pwm*(per_position_ic[:,None])\n",
    "\n",
    "\n",
    "def plot_a(ax, base, left_edge, height, color):\n",
    "    a_polygon_coords = [\n",
    "        np.array([\n",
    "           [0.0, 0.0],\n",
    "           [0.5, 1.0],\n",
    "           [0.5, 0.8],\n",
    "           [0.2, 0.0],\n",
    "        ]),\n",
    "        np.array([\n",
    "           [1.0, 0.0],\n",
    "           [0.5, 1.0],\n",
    "           [0.5, 0.8],\n",
    "           [0.8, 0.0],\n",
    "        ]),\n",
    "        np.array([\n",
    "           [0.225, 0.45],\n",
    "           [0.775, 0.45],\n",
    "           [0.85, 0.3],\n",
    "           [0.15, 0.3],\n",
    "        ])\n",
    "    ]\n",
    "    for polygon_coords in a_polygon_coords:\n",
    "        ax.add_patch(matplotlib.patches.Polygon((np.array([1,height])[None,:]*polygon_coords\n",
    "                                                 + np.array([left_edge,base])[None,:]),\n",
    "                                                facecolor=color, edgecolor=color))\n",
    "\n",
    "\n",
    "def plot_c(ax, base, left_edge, height, color):\n",
    "    ax.add_patch(matplotlib.patches.Ellipse(xy=[left_edge+0.65, base+0.5*height], width=1.3, height=height,\n",
    "                                            facecolor=color, edgecolor=color))\n",
    "    ax.add_patch(matplotlib.patches.Ellipse(xy=[left_edge+0.65, base+0.5*height], width=0.7*1.3, height=0.7*height,\n",
    "                                            facecolor='white', edgecolor='white'))\n",
    "    ax.add_patch(matplotlib.patches.Rectangle(xy=[left_edge+1, base], width=1.0, height=height,\n",
    "                                            facecolor='white', edgecolor='white', fill=True))\n",
    "\n",
    "\n",
    "def plot_g(ax, base, left_edge, height, color):\n",
    "    ax.add_patch(matplotlib.patches.Ellipse(xy=[left_edge+0.65, base+0.5*height], width=1.3, height=height,\n",
    "                                            facecolor=color, edgecolor=color))\n",
    "    ax.add_patch(matplotlib.patches.Ellipse(xy=[left_edge+0.65, base+0.5*height], width=0.7*1.3, height=0.7*height,\n",
    "                                            facecolor='white', edgecolor='white'))\n",
    "    ax.add_patch(matplotlib.patches.Rectangle(xy=[left_edge+1, base], width=1.0, height=height,\n",
    "                                            facecolor='white', edgecolor='white', fill=True))\n",
    "    ax.add_patch(matplotlib.patches.Rectangle(xy=[left_edge+0.825, base+0.085*height], width=0.174, height=0.415*height,\n",
    "                                            facecolor=color, edgecolor=color, fill=True))\n",
    "    ax.add_patch(matplotlib.patches.Rectangle(xy=[left_edge+0.625, base+0.35*height], width=0.374, height=0.15*height,\n",
    "                                            facecolor=color, edgecolor=color, fill=True))\n",
    "\n",
    "\n",
    "def plot_t(ax, base, left_edge, height, color):\n",
    "    ax.add_patch(matplotlib.patches.Rectangle(xy=[left_edge+0.4, base],\n",
    "                  width=0.2, height=height, facecolor=color, edgecolor=color, fill=True))\n",
    "    ax.add_patch(matplotlib.patches.Rectangle(xy=[left_edge, base+0.8*height],\n",
    "                  width=1.0, height=0.2*height, facecolor=color, edgecolor=color, fill=True))\n",
    "\n",
    "default_colors = {0:'green', 1:'blue', 2:'orange', 3:'red'}\n",
    "default_plot_funcs = {0:plot_a, 1:plot_c, 2:plot_g, 3:plot_t}\n",
    "def plot_weights_given_ax(ax, array,\n",
    "                 figsize=(20,2),\n",
    "                 height_padding_factor=0.2,\n",
    "                 length_padding=1.0,\n",
    "                 subticks_frequency=1.0,\n",
    "                 colors=default_colors,\n",
    "                 plot_funcs=default_plot_funcs,\n",
    "                 highlight={},\n",
    "                 ylabel=\"\"):\n",
    "    if len(array.shape)==3:\n",
    "        array = np.squeeze(array)\n",
    "    assert len(array.shape)==2, array.shape\n",
    "    if (array.shape[0]==4 and array.shape[1] != 4):\n",
    "        array = array.transpose(1,0)\n",
    "    assert array.shape[1]==4\n",
    "    max_pos_height = 0.0\n",
    "    min_neg_height = 0.0\n",
    "    heights_at_positions = []\n",
    "    depths_at_positions = []\n",
    "    for i in range(array.shape[0]):\n",
    "        #sort from smallest to highest magnitude\n",
    "        acgt_vals = sorted(enumerate(array[i,:]), key=lambda x: abs(x[1]))\n",
    "        positive_height_so_far = 0.0\n",
    "        negative_height_so_far = 0.0\n",
    "        for letter in acgt_vals:\n",
    "            plot_func = plot_funcs[letter[0]]\n",
    "            color=colors[letter[0]]\n",
    "            if (letter[1] > 0):\n",
    "                height_so_far = positive_height_so_far\n",
    "                positive_height_so_far += letter[1]                \n",
    "            else:\n",
    "                height_so_far = negative_height_so_far\n",
    "                negative_height_so_far += letter[1]\n",
    "            plot_func(ax=ax, base=height_so_far, left_edge=i, height=letter[1], color=color)\n",
    "        max_pos_height = max(max_pos_height, positive_height_so_far)\n",
    "        min_neg_height = min(min_neg_height, negative_height_so_far)\n",
    "        heights_at_positions.append(positive_height_so_far)\n",
    "        depths_at_positions.append(negative_height_so_far)\n",
    "\n",
    "    #now highlight any desired positions; the key of\n",
    "    #the highlight dict should be the color\n",
    "    for color in highlight:\n",
    "        for start_pos, end_pos in highlight[color]:\n",
    "            assert start_pos >= 0.0 and end_pos <= array.shape[0]\n",
    "            min_depth = np.min(depths_at_positions[start_pos:end_pos])\n",
    "            max_height = np.max(heights_at_positions[start_pos:end_pos])\n",
    "            ax.add_patch(\n",
    "                matplotlib.patches.Rectangle(xy=[start_pos,min_depth],\n",
    "                    width=end_pos-start_pos,\n",
    "                    height=max_height-min_depth,\n",
    "                    edgecolor=color, fill=False))\n",
    "            \n",
    "    ax.set_xlim(-length_padding, array.shape[0]+length_padding)\n",
    "    ax.xaxis.set_ticks(np.arange(0.0, array.shape[0]+1, subticks_frequency))\n",
    "    height_padding = max(abs(min_neg_height)*(height_padding_factor),\n",
    "                         abs(max_pos_height)*(height_padding_factor))\n",
    "    ax.set_ylim(min_neg_height-height_padding, max_pos_height+height_padding)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.yaxis.label.set_fontsize(15)\n",
    "\n",
    "\n",
    "def plot_weights(array,\n",
    "                 figsize=(20,2),\n",
    "                 **kwargs):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_subplot(111) \n",
    "    plot_weights_given_ax(ax=ax, array=array,**kwargs)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_score_track_given_ax(arr, ax, threshold=None, **kwargs):\n",
    "    ax.plot(np.arange(len(arr)), arr, **kwargs)\n",
    "    if (threshold is not None):\n",
    "        ax.plot([0, len(arr)-1], [threshold, threshold])\n",
    "    ax.set_xlim(0,len(arr)-1)\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "def plot_score_track(arr, threshold=None, figsize=(20,2), **kwargs):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_subplot(111) \n",
    "    plot_score_track_given_ax(arr, threshold=threshold, ax=ax, **kwargs) \n",
    "    plt.show()\n",
    "\n",
    "def plot_pwm(weights, figsize=(16, 2), plot_y_ticks=True, y_min=None, y_max=None, save_figs=False, fig_name=\"default\") :\n",
    "    colors = {0:'green', 1:'blue', 2:'orange', 3:'red'}\n",
    "    \n",
    "    plot_funcs = {0: plot_a, 1: plot_c, \n",
    "                  2: plot_g, 3: plot_t}\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    \n",
    "    ax = fig.add_subplot(111) \n",
    "    \n",
    "    plot_weights_given_ax(ax=ax, array=weights, \n",
    "                                       height_padding_factor=0.2,\n",
    "                                       length_padding=1.0, \n",
    "                                       subticks_frequency=1.0, \n",
    "                                       colors=colors, plot_funcs=plot_funcs, \n",
    "                                       highlight={}, ylabel=\"\")\n",
    "\n",
    "    plt.sca(ax)\n",
    "    \n",
    "    plt.xticks([], [])\n",
    "    plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "    \n",
    "    if plot_y_ticks :\n",
    "        plt.yticks(fontsize=12)\n",
    "    else :\n",
    "        plt.yticks([], [])\n",
    "    \n",
    "    if y_min is not None and y_max is not None :\n",
    "        plt.ylim(y_min, y_max)\n",
    "    elif y_min is not None :\n",
    "        plt.ylim(y_min)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_figs :\n",
    "        plt.savefig(fig_name + \".png\", transparent=True, dpi=600)\n",
    "        plt.savefig(fig_name + \".eps\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib.text import TextPath\n",
    "from matplotlib.patches import PathPatch, Rectangle\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "def dna_letter_at(letter, x, y, yscale=1, ax=None, color=None, alpha=1.0):\n",
    "\n",
    "    fp = FontProperties(family=\"DejaVu Sans\", weight=\"bold\")\n",
    "    globscale = 1.35\n",
    "    LETTERS = {\t\"T\" : TextPath((-0.305, 0), \"T\", size=1, prop=fp),\n",
    "                \"G\" : TextPath((-0.384, 0), \"G\", size=1, prop=fp),\n",
    "                \"A\" : TextPath((-0.35, 0), \"A\", size=1, prop=fp),\n",
    "                \"C\" : TextPath((-0.366, 0), \"C\", size=1, prop=fp),\n",
    "                \"UP\" : TextPath((-0.488, 0), '$\\\\Uparrow$', size=1, prop=fp),\n",
    "                \"DN\" : TextPath((-0.488, 0), '$\\\\Downarrow$', size=1, prop=fp),\n",
    "                \"(\" : TextPath((-0.25, 0), \"(\", size=1, prop=fp),\n",
    "                \".\" : TextPath((-0.125, 0), \"-\", size=1, prop=fp),\n",
    "                \")\" : TextPath((-0.1, 0), \")\", size=1, prop=fp)}\n",
    "    COLOR_SCHEME = {'G': 'orange',#'orange', \n",
    "                    'A': 'green',#'red', \n",
    "                    'C': 'blue',#'blue', \n",
    "                    'T': 'red',#'darkgreen',\n",
    "                    'UP': 'green', \n",
    "                    'DN': 'red',\n",
    "                    '(': 'black',\n",
    "                    '.': 'black', \n",
    "                    ')': 'black'}\n",
    "\n",
    "\n",
    "    text = LETTERS[letter]\n",
    "\n",
    "    chosen_color = COLOR_SCHEME[letter]\n",
    "    if color is not None :\n",
    "        chosen_color = color\n",
    "\n",
    "    t = mpl.transforms.Affine2D().scale(1*globscale, yscale*globscale) + \\\n",
    "        mpl.transforms.Affine2D().translate(x,y) + ax.transData\n",
    "    p = PathPatch(text, lw=0, fc=chosen_color, alpha=alpha, transform=t)\n",
    "    if ax != None:\n",
    "        ax.add_artist(p)\n",
    "    return p\n",
    "\n",
    "def plot_seq_scores(importance_scores, figsize=(16, 2), plot_y_ticks=True, y_min=None, y_max=None, save_figs=False, fig_name=\"default\") :\n",
    "\n",
    "    importance_scores = importance_scores.T\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    \n",
    "    ref_seq = \"\"\n",
    "    for j in range(importance_scores.shape[1]) :\n",
    "        argmax_nt = np.argmax(np.abs(importance_scores[:, j]))\n",
    "        \n",
    "        if argmax_nt == 0 :\n",
    "            ref_seq += \"A\"\n",
    "        elif argmax_nt == 1 :\n",
    "            ref_seq += \"C\"\n",
    "        elif argmax_nt == 2 :\n",
    "            ref_seq += \"G\"\n",
    "        elif argmax_nt == 3 :\n",
    "            ref_seq += \"T\"\n",
    "\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    for i in range(0, len(ref_seq)) :\n",
    "        mutability_score = np.sum(importance_scores[:, i])\n",
    "        color = None\n",
    "        dna_letter_at(ref_seq[i], i + 0.5, 0, mutability_score, ax, color=color)\n",
    "    \n",
    "    plt.sca(ax)\n",
    "    plt.xticks([], [])\n",
    "    plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "    \n",
    "    plt.xlim((0, len(ref_seq)))\n",
    "    \n",
    "    #plt.axis('off')\n",
    "    \n",
    "    if plot_y_ticks :\n",
    "        plt.yticks(fontsize=12)\n",
    "    else :\n",
    "        plt.yticks([], [])\n",
    "    \n",
    "    if y_min is not None and y_max is not None :\n",
    "        plt.ylim(y_min, y_max)\n",
    "    elif y_min is not None :\n",
    "        plt.ylim(y_min)\n",
    "    else :\n",
    "        plt.ylim(\n",
    "            np.min(importance_scores) - 0.1 * np.max(np.abs(importance_scores)),\n",
    "            np.max(importance_scores) + 0.1 * np.max(np.abs(importance_scores))\n",
    "        )\n",
    "    \n",
    "    plt.axhline(y=0., color='black', linestyle='-', linewidth=1)\n",
    "\n",
    "    #for axis in fig.axes :\n",
    "    #    axis.get_xaxis().set_visible(False)\n",
    "    #    axis.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_figs :\n",
    "        plt.savefig(fig_name + \".png\", transparent=True, dpi=300)\n",
    "        plt.savefig(fig_name + \".eps\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_pwm_2(pwm, figsize=(16, 2), plot_y_ticks=True, y_min=None, y_max=None, save_figs=False, fig_name=\"default\") :\n",
    "    \n",
    "    fig = plt.figure(figsize=figsize)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    height_base = 0.\n",
    "    logo_height = 1.0\n",
    "    \n",
    "    for j in range(0, pwm.shape[0]) :\n",
    "        sort_index = np.argsort(pwm[j, :])\n",
    "\n",
    "        for ii in range(0, 4) :\n",
    "            i = sort_index[ii]\n",
    "\n",
    "            nt_prob = pwm[j, i]# * conservation[j]\n",
    "\n",
    "            nt = ''\n",
    "            if i == 0 :\n",
    "                nt = 'A'\n",
    "            elif i == 1 :\n",
    "                nt = 'C'\n",
    "            elif i == 2 :\n",
    "                nt = 'G'\n",
    "            elif i == 3 :\n",
    "                nt = 'T'\n",
    "\n",
    "            color = None\n",
    "            if ii == 0 :\n",
    "                dna_letter_at(nt, j + 0.5, height_base, nt_prob * logo_height, ax, color=color)\n",
    "            else :\n",
    "                prev_prob = np.sum(pwm[j, sort_index[:ii]]) * logo_height # * conservation[j]\n",
    "                dna_letter_at(nt, j + 0.5, height_base + prev_prob, nt_prob * logo_height, ax, color=color)\n",
    "    \n",
    "    plt.sca(ax)\n",
    "    plt.xticks([], [])\n",
    "    plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "    \n",
    "    plt.xlim((0, pwm.shape[0]))\n",
    "    \n",
    "    #plt.axis('off')\n",
    "    \n",
    "    if plot_y_ticks :\n",
    "        plt.yticks(fontsize=12)\n",
    "    else :\n",
    "        plt.yticks([], [])\n",
    "    \n",
    "    if y_min is not None and y_max is not None :\n",
    "        plt.ylim(y_min, y_max)\n",
    "    elif y_min is not None :\n",
    "        plt.ylim(y_min)\n",
    "    else :\n",
    "        plt.ylim(\n",
    "            min(0., np.min(np.sum(pwm, axis=-1))) - 0.01 * np.max(np.abs(np.sum(pwm, axis=-1))),\n",
    "            max(0., np.max(np.sum(pwm, axis=-1))) + 0.01 * np.max(np.abs(np.sum(pwm, axis=-1)))\n",
    "        )\n",
    "    \n",
    "    print(np.min(np.sum(pwm, axis=-1)) - 0.1 * np.max(np.abs(np.sum(pwm, axis=-1))))\n",
    "    print(np.max(np.sum(pwm, axis=-1)) + 0.1 * np.max(np.abs(np.sum(pwm, axis=-1))))\n",
    "    \n",
    "    plt.axhline(y=0., color='black', linestyle='-', linewidth=1)\n",
    "\n",
    "    #for axis in fig.axes :\n",
    "    #    axis.get_xaxis().set_visible(False)\n",
    "    #    axis.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_figs :\n",
    "        plt.savefig(fig_name + \".png\", transparent=True, dpi=300)\n",
    "        plt.savefig(fig_name + \".eps\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "#One-hot-encoder\n",
    "class SequenceEncoder :\n",
    "    \n",
    "    def __init__(self, encoder_type_id, encode_dims) :\n",
    "        self.encoder_type_id = encoder_type_id\n",
    "        self.encode_dims = encode_dims\n",
    "    \n",
    "    def encode(self, seq) :\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def encode_inplace(self, seq, encoding) :\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def encode_inplace_sparse(self, seq, encoding_mat, row_index) :\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def decode(self, encoding) :\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def decode_sparse(self, encoding_mat, row_index) :\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def __call__(self, seq) :\n",
    "        return self.encode(seq)\n",
    "    \n",
    "class OneHotEncoder(SequenceEncoder) :\n",
    "    \n",
    "    def __init__(self, seq_length, channel_map) :\n",
    "        super(OneHotEncoder, self).__init__('onehot', (seq_length, len(channel_map)))\n",
    "        \n",
    "        self.seq_len = seq_length\n",
    "        self.n_channels = len(channel_map)\n",
    "        self.encode_map = channel_map\n",
    "        self.decode_map = {\n",
    "            val : key for key, val in channel_map.items()\n",
    "        }\n",
    "    \n",
    "    def encode(self, seq) :\n",
    "        encoding = np.zeros((self.seq_len, self.n_channels))\n",
    "        \n",
    "        for i in range(len(seq)) :\n",
    "            if seq[i] in self.encode_map :\n",
    "                channel_ix = self.encode_map[seq[i]]\n",
    "                encoding[i, channel_ix] = 1.\n",
    "\n",
    "        return encoding\n",
    "    \n",
    "    def encode_inplace(self, seq, encoding) :\n",
    "        for i in range(len(seq)) :\n",
    "            if seq[i] in self.encode_map :\n",
    "                channel_ix = self.encode_map[seq[i]]\n",
    "                encoding[i, channel_ix] = 1.\n",
    "    \n",
    "    def encode_inplace_sparse(self, seq, encoding_mat, row_index) :\n",
    "        raise NotImplementError()\n",
    "    \n",
    "    def decode(self, encoding) :\n",
    "        seq = ''\n",
    "    \n",
    "        for pos in range(0, encoding.shape[0]) :\n",
    "            argmax_nt = np.argmax(encoding[pos, :])\n",
    "            max_nt = np.max(encoding[pos, :])\n",
    "            if max_nt == 1 :\n",
    "                seq += self.decode_map[argmax_nt]\n",
    "            else :\n",
    "                seq += self.decode_map[self.n_channels - 1]\n",
    "\n",
    "        return seq\n",
    "    \n",
    "    def decode_sparse(self, encoding_mat, row_index) :\n",
    "        encoding = np.array(encoding_mat[row_index, :].todense()).reshape(-1, 4)\n",
    "        return self.decode(encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (5267, 10, 205, 4)\n",
      "m.shape = (5267, 10)\n",
      "l.shape = (5267, 10)\n",
      "c.shape = (5267, 10, 28)\n",
      "y.shape = (5267, 10, 28)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('polyadb_features_pas_3_utr3_perturb.csv', sep='\\t')\n",
    "\n",
    "save_dict = np.load(\"polyadb_features_pas_3_utr3_perturb.npz\")\n",
    "x, m, l, c, y = save_dict['x'], save_dict['m'], save_dict['l'], save_dict['c'], save_dict['y']\n",
    "\n",
    "print(\"x.shape = \" + str(x.shape))\n",
    "print(\"m.shape = \" + str(m.shape))\n",
    "print(\"l.shape = \" + str(l.shape))\n",
    "print(\"c.shape = \" + str(c.shape))\n",
    "print(\"y.shape = \" + str(y.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5267, 10)\n"
     ]
    }
   ],
   "source": [
    "#Cache/Load APARENT2 baseline score\n",
    "\n",
    "#np.save(\"polyadb_features_pas_3_utr3_perturb_aparent2_all_scores\", s)\n",
    "s = np.load(\"polyadb_features_pas_3_utr3_perturb_aparent2_all_scores.npy\")\n",
    "\n",
    "print(s.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5267, 28)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dist_index = np.array([np.nonzero(m[i, :])[0][-1] for i in range(m.shape[0])])\n",
    "\n",
    "dist_mask = np.zeros(m.shape)\n",
    "for i in range(m.shape[0]) :\n",
    "    dist_mask[i, dist_index[i]] = 1.\n",
    "\n",
    "y_dist = []\n",
    "for i in range(y.shape[0]) :\n",
    "    y_dist.append(y[i:i+1, dist_index[i], :])\n",
    "\n",
    "y_dist = np.concatenate(y_dist, axis=0)\n",
    "\n",
    "print(y_dist.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:15: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#Load tissue-specific PAS model and generate scores for select tissue types\n",
    "\n",
    "subset_cell_types = np.array([\n",
    "    'NT',\n",
    "    'CPSF4',\n",
    "    'CPSF6',\n",
    "    'CSTF1',\n",
    "    'CSTF3',\n",
    "    'FIP1L1',\n",
    "    'NUDT21',\n",
    "    'RBBP6',\n",
    "    'SRSF3',\n",
    "    'SYMPK',\n",
    "    'THOC5'\n",
    "], dtype=np.object)\n",
    "\n",
    "subset_cell_type_dict = {\n",
    "    cell_type : cell_type_i for cell_type_i, cell_type in enumerate(subset_cell_types)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:32: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "#Define tissue-/cell- types\n",
    "\n",
    "cell_types = np.array([\n",
    "    'rpm',\n",
    "    'NT',\n",
    "    'CDC73',\n",
    "    'CPSF1',\n",
    "    'CPSF2',\n",
    "    'CPSF3',\n",
    "    'CPSF3L',\n",
    "    'CPSF4',\n",
    "    'CPSF6',\n",
    "    'CSTF1',\n",
    "    'CSTF3',\n",
    "    'CTR9',\n",
    "    'FIP1L1',\n",
    "    'LEO1',\n",
    "    'NUDT21',\n",
    "    'PABPC1',\n",
    "    'PABPN1',\n",
    "    'PAF1',\n",
    "    'PAPOLA',\n",
    "    'PCF11',\n",
    "    'RBBP6',\n",
    "    'RPRD1A',\n",
    "    'RPRD1B',\n",
    "    'SCAF8',\n",
    "    'SF3A1',\n",
    "    'SRSF3',\n",
    "    'SYMPK',\n",
    "    'THOC5'\n",
    "], dtype=np.object)\n",
    "\n",
    "cell_type_dict = {\n",
    "    cell_type : cell_type_i for cell_type_i, cell_type in enumerate(cell_types)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#PAS network definition\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda\n",
    "from keras.layers import Conv2D, LocallyConnected2D, MaxPooling2D, GlobalMaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, Conv1D, LocallyConnected1D, MaxPooling1D, LSTM, ConvLSTM2D, GRU, CuDNNLSTM, CuDNNGRU, BatchNormalization, LocallyConnected2D, Permute, TimeDistributed, Bidirectional\n",
    "from keras.layers import Concatenate, Reshape, Softmax, Conv2DTranspose, Embedding, Multiply\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import Progbar\n",
    "from keras.layers.merge import _Merge\n",
    "import keras.losses\n",
    "\n",
    "def load_pas_network(n_cell_types=1, n_dil=6, n_channels=32, filter_size=3, filter_size_0=5, nonneg_up_to=0) :\n",
    "    \n",
    "    conv_0 = Conv2D(n_channels, kernel_size=(1, filter_size_0), kernel_constraint=keras.constraints.NonNeg() if nonneg_up_to > 0 else None, padding='same', activation='relu', name='pasnet_conv2d_0')\n",
    "    \n",
    "    drop_0 = Dropout(0.5, name='pasnet_drop_0')\n",
    "    \n",
    "    convs = [\n",
    "        Conv2D(n_channels, kernel_size=(1, filter_size), kernel_constraint=keras.constraints.NonNeg() if i < nonneg_up_to else None, padding='same', activation='relu', dilation_rate=2**i, name='pasnet_conv2d_' + str(i)) for i in range(1, n_dil+1)\n",
    "    ]\n",
    "    \n",
    "    drops = [\n",
    "        Dropout(0.5, name='pasnet_drop_' + str(i)) for i in range(1, n_dil+1)\n",
    "    ]\n",
    "    \n",
    "    adds = [\n",
    "        Lambda(lambda x: x[0] + x[1], name='pasnet_add_' + str(i)) for i in range(1, n_dil+1)\n",
    "    ]\n",
    "    \n",
    "    pool = Lambda(lambda x: K.mean(x, axis=(1, 2)))\n",
    "\n",
    "    final_dense = Dense(n_cell_types*3, activation='linear', kernel_initializer='zeros', bias_initializer='zeros', name='pasnet_dense_2')\n",
    "    final_reshape = Lambda(lambda x: K.reshape(x, (K.shape(x)[0], n_cell_types, 3)))\n",
    "    \n",
    "    def _net_func(sequence_input) :\n",
    "        \n",
    "        x = drop_0(conv_0(sequence_input))\n",
    "\n",
    "        for i in range(1, n_dil+1):\n",
    "            x = adds[i-1]([drops[i-1](convs[i-1](x)), x])\n",
    "\n",
    "        pool_out = pool(x)\n",
    "\n",
    "        final_dense_out = final_dense(pool_out)\n",
    "        \n",
    "        return final_reshape(final_dense_out)\n",
    "\n",
    "    return _net_func\n",
    "\n",
    "def _load_pas_model(model_name, n_cell_types=1) :\n",
    "    \n",
    "    seq_input = Input(shape=(1, 205, 4), name='seq_input')\n",
    "    \n",
    "    pas_net = load_pas_network(n_cell_types=n_cell_types)\n",
    "    \n",
    "    pred_output = pas_net(seq_input)\n",
    "    \n",
    "    pas_model = Model(seq_input, pred_output)\n",
    "    pas_model.load_weights(model_name, by_name=True)\n",
    "    pas_model.compile(loss='mean_squared_error', optimizer=keras.optimizers.SGD(0.1))\n",
    "    \n",
    "    return pas_model\n",
    "\n",
    "def _predict_multi_pas(pas_model, x, batch_size=32) :\n",
    "    \n",
    "    y_preds = []\n",
    "    for k in range(x.shape[1]) :\n",
    "        y_preds.append(pas_model.predict(x=[x[:, k:k+1, ...]], batch_size=32)[:, None, ...])\n",
    "    \n",
    "    return np.concatenate(y_preds, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model parameters\n",
    "\n",
    "n_bootstraps = 5\n",
    "n_cell_types = subset_cell_types.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 15:42:59.365982: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2023-05-09 15:42:59.501432: E tensorflow/stream_executor/cuda/cuda_driver.cc:322] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-05-09 15:42:59.501485: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (johannes-design-interpret-1): /proc/driver/nvidia/version does not exist\n",
      "2023-05-09 15:42:59.527497: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
      "2023-05-09 15:42:59.529506: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5578db561ff0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-09 15:42:59.529537: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nts_ensemble = np.concatenate([_predict_multi_pas(tissue_models[bootstrap_ix], x, batch_size=32)[..., None] for bootstrap_ix in range(n_bootstraps)], axis=-1)\\n\\nts = np.mean(ts_ensemble, axis=-1)\\n\\nprint(\"ts.shape = \" + str(ts.shape))\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict tissue model scores\n",
    "\n",
    "tissue_models = [\n",
    "    _load_pas_model(\"saved_models/perturb_resnet_utr3_covar_drop_ensemble_\" + str(bootstrap_ix) + \"_pas_model.h5\", n_cell_types=n_cell_types) for bootstrap_ix in range(n_bootstraps)\n",
    "]\n",
    "'''\n",
    "ts_ensemble = np.concatenate([_predict_multi_pas(tissue_models[bootstrap_ix], x, batch_size=32)[..., None] for bootstrap_ix in range(n_bootstraps)], axis=-1)\n",
    "\n",
    "ts = np.mean(ts_ensemble, axis=-1)\n",
    "\n",
    "print(\"ts.shape = \" + str(ts.shape))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5267, 10, 11, 3, 5)\n",
      "(5267, 10, 11, 3)\n"
     ]
    }
   ],
   "source": [
    "#Cache/Load tissue scores\n",
    "'''\n",
    "np.save(\"polyadb_features_pas_3_utr3_perturb_resnet_covar_drop_ts_ensemble\", ts_ensemble)\n",
    "np.save(\"polyadb_features_pas_3_utr3_perturb_resnet_covar_drop_ts\", ts)\n",
    "'''\n",
    "ts_ensemble = np.load(\"polyadb_features_pas_3_utr3_perturb_resnet_covar_drop_ts_ensemble.npy\")\n",
    "ts = np.load(\"polyadb_features_pas_3_utr3_perturb_resnet_covar_drop_ts.npy\")\n",
    "\n",
    "print(ts_ensemble.shape)\n",
    "print(ts.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute normalization statistics\n",
    "\n",
    "cell_type_ixs = [cell_type_dict[ct] for ct in subset_cell_types.tolist()]\n",
    "\n",
    "flat_x = np.reshape(x, (x.shape[0] * x.shape[1], 1, 205, 4))\n",
    "flat_ts_ensemble = np.reshape(ts_ensemble, (x.shape[0] * x.shape[1], n_cell_types, n_bootstraps, 3))\n",
    "flat_ts = np.reshape(ts, (x.shape[0] * x.shape[1], n_cell_types, 3))\n",
    "flat_s = np.reshape(s, (x.shape[0] * x.shape[1],))\n",
    "flat_y = np.reshape(y[:, :, cell_type_ixs], (x.shape[0] * x.shape[1], n_cell_types))\n",
    "flat_gene_ind = np.reshape(np.tile(np.arange(x.shape[0])[:, None], (1, x.shape[1])), (x.shape[0] * x.shape[1],))\n",
    "flat_pas_ind = np.reshape(np.tile(np.arange(x.shape[1])[None, :], (x.shape[0], 1)), (x.shape[0] * x.shape[1],))\n",
    "\n",
    "flat_m = np.reshape(m, (x.shape[0] * x.shape[1],))\n",
    "flat_dist_mask = np.reshape(dist_mask, (x.shape[0] * x.shape[1],))\n",
    "\n",
    "flat_keep_index = np.nonzero(flat_m >= 1)[0]\n",
    "\n",
    "flat_x = flat_x[flat_keep_index, ...]\n",
    "flat_ts_ensemble = flat_ts_ensemble[flat_keep_index, ...]\n",
    "flat_ts = flat_ts[flat_keep_index, ...]\n",
    "flat_s = flat_s[flat_keep_index, ...]\n",
    "flat_y = flat_y[flat_keep_index, ...]\n",
    "flat_gene_ind = flat_gene_ind[flat_keep_index, ...]\n",
    "flat_pas_ind = flat_pas_ind[flat_keep_index, ...]\n",
    "\n",
    "flat_m = flat_m[flat_keep_index, ...]\n",
    "flat_dist_mask = flat_dist_mask[flat_keep_index, ...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct masks for proximal/middle/distal sites\n",
    "\n",
    "flat_prox_mask = np.array((flat_pas_ind == 0), dtype=np.float32)\n",
    "flat_middle_mask = 1. - flat_dist_mask - flat_prox_mask\n",
    "\n",
    "flat_masks = [\n",
    "    flat_prox_mask,\n",
    "    flat_middle_mask,\n",
    "    flat_dist_mask\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load processed (flattened) PAS IDs from original dataframe\n",
    "\n",
    "flat_ids = np.load(\"polyadb_features_pas_3_utr3_perturb_flat_ids.npy\", allow_pickle=True)\n",
    "\n",
    "#Compile and flatten gene names\n",
    "flat_gene_names = []\n",
    "for _, row in df.iterrows() :\n",
    "    flat_gene_names.extend([row['gene'] for k in range(m.shape[1]) if row['pas_exists_' + str(k)] == 1])\n",
    "\n",
    "flat_gene_names = np.array(flat_gene_names, dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flat_scores.shape = (11, 3, 14764, 1, 205, 4)\n",
      "(bootstrap_ix = 0) flat_scores.shape = (11, 3, 14764, 1, 205, 4)\n",
      "(bootstrap_ix = 1) flat_scores.shape = (11, 3, 14764, 1, 205, 4)\n",
      "(bootstrap_ix = 2) flat_scores.shape = (11, 3, 14764, 1, 205, 4)\n"
     ]
    }
   ],
   "source": [
    "#Re-load gated importance scores\n",
    "\n",
    "flat_scores = np.load(\"polyadb_features_pas_3_utr3_perturb_resnet_covar_drop_flat_g_scores.npy\")\n",
    "flat_scores = np.tile(flat_scores, (1, 1, 1, 1, 1, 4)) * flat_x[None, None, ...]\n",
    "\n",
    "print(\"flat_scores.shape = \" + str(flat_scores.shape))\n",
    "\n",
    "#Re-load gated importance scores (bootstrap replicates)\n",
    "\n",
    "n_bootstraps_ism = 3\n",
    "\n",
    "flat_scores_ensemble = []\n",
    "\n",
    "for bootstrap_ix in range(n_bootstraps_ism) :\n",
    "    flat_scores_curr = np.load(\"polyadb_features_pas_3_utr3_perturb_resnet_covar_drop_flat_g_scores_bootstrap_\" + str(bootstrap_ix) + \".npy\")\n",
    "    flat_scores_curr = np.tile(flat_scores_curr, (1, 1, 1, 1, 1, 4)) * flat_x[None, None, ...]\n",
    "    \n",
    "    flat_scores_ensemble.append(flat_scores_curr)\n",
    "    \n",
    "    print(\"(bootstrap_ix = \" + str(bootstrap_ix) + \") flat_scores.shape = \" + str(flat_scores_curr.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge proximal/middle/distal predictions and ISM scores\n",
    "\n",
    "flat_ts_merged = np.zeros((flat_x.shape[0], n_cell_types))\n",
    "\n",
    "flat_ts_merged[flat_prox_mask == 1., ...] = flat_ts[flat_prox_mask == 1., ..., 0]\n",
    "flat_ts_merged[flat_middle_mask == 1., ...] = flat_ts[flat_middle_mask == 1., ..., 1]\n",
    "flat_ts_merged[flat_dist_mask == 1., ...] = flat_ts[flat_dist_mask == 1., ..., 2]\n",
    "\n",
    "flat_scores_merged = np.zeros((n_cell_types, flat_x.shape[0], 1, 205, 4))\n",
    "\n",
    "flat_scores_merged[:, flat_prox_mask == 1., ...] = flat_scores[:, 0, flat_prox_mask == 1., ...]\n",
    "flat_scores_merged[:, flat_middle_mask == 1., ...] = flat_scores[:, 1, flat_middle_mask == 1., ...]\n",
    "flat_scores_merged[:, flat_dist_mask == 1., ...] = flat_scores[:, 2, flat_dist_mask == 1., ...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mononuc_native = [0.3, 0.17, 0.18, 0.35]\n",
      "mononuc_neutral = [0.31, 0.17, 0.17, 0.35]\n",
      "mononuc_weak = [0.28, 0.2, 0.21, 0.31]\n",
      "mononuc_stong = [0.3, 0.15, 0.16, 0.39]\n"
     ]
    }
   ],
   "source": [
    "#Calculate 'native' background nucleotide frequencies\n",
    "s_qtl_lo = np.quantile(flat_s, q=0.0)\n",
    "s_qtl_hi = np.quantile(flat_s, q=1.0)\n",
    "\n",
    "filter_index = np.nonzero((flat_s >= s_qtl_lo) & (flat_s < s_qtl_hi))[0]\n",
    "\n",
    "#Calculate filtered mononucleotide background frequencies\n",
    "mononuc_native = np.sum(flat_x[filter_index, 0, 0:146, :], axis=(0, 1)) / np.sum(flat_x[filter_index, 0, 0:146, :])\n",
    "\n",
    "print(\"mononuc_native = \" + str(np.round(mononuc_native, 2).tolist()))\n",
    "\n",
    "#Calculate 'neutral' background nucleotide frequencies\n",
    "s_qtl_lo = np.quantile(flat_s, q=0.45)\n",
    "s_qtl_hi = np.quantile(flat_s, q=0.55)\n",
    "\n",
    "filter_index = np.nonzero((flat_s >= s_qtl_lo) & (flat_s < s_qtl_hi))[0]\n",
    "\n",
    "#Calculate filtered mononucleotide background frequencies\n",
    "mononuc_neutral = np.sum(flat_x[filter_index, 0, 0:146, :], axis=(0, 1)) / np.sum(flat_x[filter_index, 0, 0:146, :])\n",
    "\n",
    "print(\"mononuc_neutral = \" + str(np.round(mononuc_neutral, 2).tolist()))\n",
    "\n",
    "#Calculate 'weak' background nucleotide frequencies\n",
    "s_qtl_lo = np.quantile(flat_s, q=0.0)\n",
    "s_qtl_hi = np.quantile(flat_s, q=0.1)\n",
    "\n",
    "filter_index = np.nonzero((flat_s >= s_qtl_lo) & (flat_s < s_qtl_hi))[0]\n",
    "\n",
    "#Calculate filtered mononucleotide background frequencies\n",
    "mononuc_weak = np.sum(flat_x[filter_index, 0, 0:146, :], axis=(0, 1)) / np.sum(flat_x[filter_index, 0, 0:146, :])\n",
    "\n",
    "print(\"mononuc_weak = \" + str(np.round(mononuc_weak, 2).tolist()))\n",
    "\n",
    "#Calculate 'stong' background nucleotide frequencies\n",
    "s_qtl_lo = np.quantile(flat_s, q=0.9)\n",
    "s_qtl_hi = np.quantile(flat_s, q=1.0)\n",
    "\n",
    "filter_index = np.nonzero((flat_s >= s_qtl_lo) & (flat_s < s_qtl_hi))[0]\n",
    "\n",
    "#Calculate filtered mononucleotide background frequencies\n",
    "mononuc_stong = np.sum(flat_x[filter_index, 0, 0:146, :], axis=(0, 1)) / np.sum(flat_x[filter_index, 0, 0:146, :])\n",
    "\n",
    "print(\"mononuc_stong = \" + str(np.round(mononuc_stong, 2).tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for sampling uniform sequences and replacing the core hexamer with a weaker variant\n",
    "\n",
    "def _sample_sequences(pred_cell_type_2_ixs=None, score_ix=0, seq_start=0, seq_end=205, n_sequences=10, save_name='default') :\n",
    "    \n",
    "    if pred_cell_type_2_ixs is None :\n",
    "        pred_cell_type_2_ixs = [cell_type_2_ix]\n",
    "    \n",
    "    save_name = save_name + \"_score_ix_\" + str(score_ix) + \"_n_sequences_\" + str(n_sequences) + \"_cse\"\n",
    "    \n",
    "    if not os.path.exists(\"./samples/\" + save_name.split(\"/\")[0]) :\n",
    "        os.makedirs(\"./samples/\" + save_name.split(\"/\")[0])\n",
    "    \n",
    "    #Get sequence encoder\n",
    "    acgt_encoder = OneHotEncoder(205, {'A':0, 'C':1, 'G':2, 'T':3})\n",
    "    \n",
    "    #Find sequences with canonical CSEs\n",
    "    cano_cses = np.array([1 if acgt_encoder.decode(flat_x[i, 0, seq_start:seq_end, :])[70:76] == 'AATAAA' else 0 for i in range(flat_x.shape[0])], dtype='int32')\n",
    "    \n",
    "    outlier_index = np.nonzero((cano_cses == 1) & (flat_masks[score_ix] == 1.))[0]\n",
    "    \n",
    "    #Shuffle index and pick n sequences\n",
    "    np.random.shuffle(outlier_index)\n",
    "    outlier_index = outlier_index[:n_sequences].tolist()\n",
    "\n",
    "    #Save sequences to file\n",
    "    with open(\"./samples/\" + save_name + \".txt\", \"w\") as f :\n",
    "        \n",
    "        diff_score_col_str = \"\"\n",
    "        for pred_cell_type_2_ix in pred_cell_type_2_ixs :\n",
    "            for sc_ix in range(3) :\n",
    "                diff_score_col_str += \"\\tdiff_ct_\" + str(pred_cell_type_2_ix) + \"_score_\" + str(sc_ix)\n",
    "        \n",
    "        f.write(\"gene_id\\tpas_id\\texperiment\\tseq\\tusage_nt\\tusage_perturb\\tusage_diff\" + diff_score_col_str + \"\\n\")\n",
    "        \n",
    "        for i in outlier_index :\n",
    "            gene_id = flat_gene_names[i]\n",
    "            pas_id = flat_ids[i]\n",
    "            experiment = 'wt'\n",
    "            wt_seq = acgt_encoder.decode(flat_x[i, 0, seq_start:seq_end, :])\n",
    "            \n",
    "            if wt_seq[70:76] != 'AATAAA' :\n",
    "                print(\"Error. Weak CSE in WT sequence.\")\n",
    "                print('' + 1)\n",
    "            \n",
    "            y_curr_nt = round(flat_y[i, 0], 4)\n",
    "            y_curr_perturb = 0.\n",
    "            \n",
    "            y_curr_diff = 0.\n",
    "            \n",
    "            pred_curr = []\n",
    "            for bootstrap_ix in range(n_bootstraps) :\n",
    "                pred_curr.append(tissue_models[bootstrap_ix].predict(x=[\n",
    "                    flat_x[i:i+1, ...]\n",
    "                ], batch_size=1, verbose=False))\n",
    "            \n",
    "            pred_curr = np.mean(np.concatenate(pred_curr, axis=0), axis=0)\n",
    "            \n",
    "            diff_score_str = \"\"\n",
    "            for pred_cell_type_2_ix in pred_cell_type_2_ixs :\n",
    "                for sc_ix in range(3) :\n",
    "                    diff_score_str += \"\\t\" + str(round(pred_curr[0, sc_ix] - pred_curr[pred_cell_type_2_ix, sc_ix], 4))\n",
    "            \n",
    "            #Store wildtype sequence\n",
    "            f.write(gene_id + \"\\t\" + pas_id + \"\\t\" + experiment + \"\\t\" + wt_seq + \"\\t\" + str(y_curr_nt) + \"\\t\" + str(y_curr_perturb) + \"\\t\" + str(y_curr_diff) + diff_score_str + \"\\n\")\n",
    "            \n",
    "            shuffled_seqs_1 = _replace_cse(wt_seq, [[70, 76]])\n",
    "            \n",
    "            for shuffle_i in range(len(shuffled_seqs_1)) :\n",
    "                \n",
    "                shuffled_seq = shuffled_seqs_1[shuffle_i]\n",
    "                \n",
    "                flat_x_shuffled = acgt_encoder.encode(shuffled_seq)[None, None, ...]\n",
    "                \n",
    "                pred_curr = []\n",
    "                for bootstrap_ix in range(n_bootstraps) :\n",
    "                    pred_curr.append(tissue_models[bootstrap_ix].predict(x=[\n",
    "                        flat_x_shuffled\n",
    "                    ], batch_size=1, verbose=False))\n",
    "\n",
    "                pred_curr = np.mean(np.concatenate(pred_curr, axis=0), axis=0)\n",
    "\n",
    "                diff_score_str = \"\"\n",
    "                for pred_cell_type_2_ix in pred_cell_type_2_ixs :\n",
    "                    for sc_ix in range(3) :\n",
    "                        diff_score_str += \"\\t\" + str(round(pred_curr[0, sc_ix] - pred_curr[pred_cell_type_2_ix, sc_ix], 4))\n",
    "\n",
    "                #Store shuffled sequence\n",
    "                f.write(gene_id + \"\\t\" + pas_id + \"\\t\" + \"replace_cse_repeat\" + str(shuffle_i) + \"\\t\" + shuffled_seq + \"\\t\" + str(0.) + \"\\t\" + str(0.) + \"\\t\" + str(0.) + diff_score_str + \"\\n\")\n",
    "\n",
    "def _replace_cse(seq, ablate_regions) :\n",
    "    \n",
    "    cses = [\n",
    "        'ATTAAA',\n",
    "        'TATAAA',\n",
    "        'AGTAAA',\n",
    "        'AATACA',\n",
    "        'CATAAA',\n",
    "        'AATATA',\n",
    "        'GATAAA',\n",
    "        'AATGAA',\n",
    "        'AAGAAA',\n",
    "        'ACTAAA',\n",
    "        'AATAGA',\n",
    "        'AATAAT',\n",
    "        'AACAAA',\n",
    "        'ATTACA',\n",
    "        'ATTATA',\n",
    "        'AACAAG',\n",
    "        'AATAAG',\n",
    "        'AATAAC',\n",
    "        'TATATA',\n",
    "    ]\n",
    "    \n",
    "    seqs_replaced = []\n",
    "    \n",
    "    for [ablate_start, ablate_end] in ablate_regions :\n",
    "        \n",
    "        for cse_ix, cse in enumerate(cses) :\n",
    "            \n",
    "            ablated_seq = seq[:ablate_start] + cse + seq[ablate_end:]\n",
    "\n",
    "            seqs_replaced.append(ablated_seq)\n",
    "\n",
    "    return seqs_replaced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- score_ix = 0 --\n",
      "-- score_ix = 2 --\n"
     ]
    }
   ],
   "source": [
    "#Store sequence variants\n",
    "\n",
    "#Parameter configuration\n",
    "n_sequences = 50\n",
    "\n",
    "experiment_prefix = 'unif_wt_'\n",
    "\n",
    "score_ixs = [0, 2]\n",
    "\n",
    "pred_cell_type_2_ixs = [4, 6, 7, 10]\n",
    "\n",
    "for score_ix in score_ixs :\n",
    "    print(\"-- score_ix = \" + str(score_ix) + \" --\")\n",
    "\n",
    "    save_name = experiment_prefix + 'score_ix_' + str(score_ix) + '/apa_perturb_v3'\n",
    "\n",
    "    _sample_sequences(\n",
    "        pred_cell_type_2_ixs=pred_cell_type_2_ixs,\n",
    "        score_ix=score_ix,\n",
    "        n_sequences=n_sequences,\n",
    "        save_name=save_name,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
